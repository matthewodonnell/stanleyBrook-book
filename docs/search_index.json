[["index.html", "The West Brook Story Chapter 1 Introduction 1.1 The West Brook", " The West Brook Story Ben Letcher 2022-05-25 Chapter 1 Introduction This book describes accessing, cleaning, and analyzing data from the West Brook Study in Whateley MA, USA. Use bookdown::render_book(\"index.Rmd\", \"bookdown::gitbook\") to force html book. bookdown::preview_chapter(\"01-modelsCMR_Flow.Rmd\", \"bookdown::gitbook\") to update just one chapter (01-modelsCMR_Flow.Rmd as example here). Use clean_book() to clean up temporary files. 1.1 The West Brook The Ecology Section at the USGS Conte Laboratory has studied fish in the West Brook since 1997. The goal is to understand the strength and direction of drivers on fish growth, movement, reproduction and survival in the wild. We hope to provide a comprehensive understanding of fish population dynamics and ultimately individual fitness (natural selection and evolution) in the study area. Interactive applications allow exploration of the raw data. "],["getData.html", "Chapter 2 Get data 2.1 Get environmental data 2.2 Electrofishing data 2.3 Capture-recapture data 2.4 Wanding data 2.5 Antenna data", " Chapter 2 Get data The server hosting the data is named osensei and is at UMass (osensei.cns.umass.edu). It can be accessed using functions in the ‘getWBData’ package. Use devtools::install_github('Conte-Ecology/westBrookData/getWBData') to install. Most of the functions will run reconnect() to connect to the server with your username and password. Run reconnect() from the console to connect if necessary. Use conDplyr to see the list of available tables on the server. Details about the ‘getWBData’ package are here. We have two types of databases: Environmental and fish The environmental database contains daily mean temperature and flow data. Flow data are from a flow extension model and are not tributary-specific. Temperature data are from tributary-specific loggers. There are four main fish databases we want to create: 1. cdWB_electro0 West Brook electrofishing data, 3 species (brook trout, brown trout and Atlantic salmon), tagged and untagged fish 2. cdWB_CMR0 West Brook electrofishing data formatted for Capture-Mark-Recapture analysis for tagged individuals 3. cdWB_wanding0 West Brook wanding (portable antenna) data, all tagged salmonids 4. cdWB_antenna0 West Brook stationary antenna data, all tagged salmonids The “0” at the end of these file names indicates that they are the initial files that will be wrangled in the next step (next chapter). “cd” stands for “core data”. The getNew_... variables determine whether the data are retrieved from the server. Change to ‘TRUE’ to get a new data frame, e.g. when there are new data on the server. getNew_envDataWB &lt;- FALSE getNew_cdWB_electro0 &lt;- FALSE getNew_cdWB_CMR0 &lt;- FALSE getNew_cdWB_wanding0 &lt;- FALSE getNew_cdWB_antenna0 &lt;- FALSE 2.1 Get environmental data library(tidyverse) if(getNew_envDataWB) { reconnect() envDataWB &lt;- tbl(conDplyr, &quot;data_daily_temperature&quot;) %&gt;% collect(n = Inf) %&gt;% full_join(tbl(conDplyr, &quot;data_flow_extension&quot;) %&gt;% collect(n = Inf), by = c(&quot;river&quot;, &quot;date&quot;)) %&gt;% select(-source) %&gt;% rename(temperature = daily_mean_temp, flow = qPredicted) %&gt;% mutate(dateDate = as_date(date), yday = yday(dateDate)) save(envDataWB, file = &#39;./data/envDataWB.RData&#39;) } else { load(file = &#39;./data/envDataWB.RData&#39;) } str(envDataWB) ## tibble [32,189 × 7] (S3: tbl_df/tbl/data.frame) ## $ river : chr [1:32189] &quot;wb jimmy&quot; &quot;wb jimmy&quot; &quot;wb jimmy&quot; &quot;wb jimmy&quot; ... ## $ date : POSIXct[1:32189], format: &quot;1997-05-14&quot; &quot;1997-05-15&quot; &quot;1997-05-16&quot; &quot;1997-05-17&quot; ... ## $ temperature : num [1:32189] 11.57 10.4 10.55 8.84 9.09 ... ## $ daily_max_temp: num [1:32189] 11.6 12.3 11.9 10.2 11.6 ... ## $ daily_min_temp: num [1:32189] 11.57 8.96 9.73 7.74 7.45 ... ## $ flow : num [1:32189] NA NA NA NA NA NA NA NA NA NA ... ## $ dateDate : Date[1:32189], format: &quot;1997-05-14&quot; &quot;1997-05-15&quot; &quot;1997-05-16&quot; &quot;1997-05-17&quot; ... ggplot(envDataWB, aes(date, flow)) + geom_point() + facet_wrap(~river) ggplot(envDataWB, aes(date, temperature)) + geom_point(size = 0.5) + facet_wrap(~river) need to add getting environmental data here 2.2 Electrofishing data This section retrieves electrofishing data, including both tagged and untagged fish. Fish were untagged if they were too small (&lt; 60 mm, 2 g wet weight) or were captured outside of the core study area (tributaries and 47 sections of the mainstem West Brook). 2.2.1 Get data # default values for createCoreData() # function (sampleType = &quot;electrofishing&quot;, baseColumns = T, # columnsToAdd = NULL, includeUntagged = F, whichDrainage = &quot;west&quot;) if(getNew_cdWB_electro0) { cdWB_electro0 &lt;- createCoreData( sampleType = &quot;electrofishing&quot;, #&quot;stationaryAntenna&quot;,&quot;portableAntenna&quot; columnsToAdd = c(&quot;sampleNumber&quot;, &quot;river&quot;, &quot;survey&quot;, &quot;pass&quot;, &quot;observedLength&quot;, &quot;observedWeight&quot;, &quot;comments&quot;), includeUntagged = TRUE, whichDrainage = &quot;west&quot; ) %&gt;% addTagProperties( columnsToAdd = c(&quot;cohort&quot;, &quot;species&quot;, &quot;dateEmigrated&quot;, &quot;sex&quot;, &quot;species&quot; ) ) %&gt;% dplyr::filter(species %in% c( &quot;bkt&quot;,&quot;bnt&quot;,&quot;ats&quot;), area %in% c(&quot;trib&quot;,&quot;inside&quot;,&quot;below&quot;,&quot;above&quot;), !is.na(sampleNumber)) %&gt;% addSampleProperties() %&gt;% addEnvironmental() save(cdWB_electro0, file = &#39;./data/cdWB_electro0.RData&#39;) } else { load(file = &#39;./data/cdWB_electro0.RData&#39;) } str(cdWB_electro0) ## tibble [91,103 × 22] (S3: tbl_df/tbl/data.frame) ## $ tag : chr [1:91103] &quot;00088cbed0&quot; &quot;00088cbed3&quot; &quot;00088cbed4&quot; &quot;00088cbed4&quot; ... ## $ detectionDate : POSIXct[1:91103], format: &quot;2013-03-25 00:00:00&quot; &quot;2012-06-07 09:03:00&quot; &quot;2013-03-29 10:08:00&quot; &quot;2013-06-25 14:51:00&quot; ... ## $ sampleName : chr [1:91103] &quot;84&quot; &quot;81&quot; &quot;84&quot; &quot;85&quot; ... ## $ sampleNumber : num [1:91103] 73 70 73 74 70 71 73 79 80 71 ... ## $ river : chr [1:91103] &quot;wb obear&quot; &quot;west brook&quot; &quot;west brook&quot; &quot;west brook&quot; ... ## $ section : chr [1:91103] &quot;7&quot; &quot;1&quot; &quot;40&quot; &quot;44&quot; ... ## $ area : chr [1:91103] &quot;trib&quot; &quot;inside&quot; &quot;inside&quot; &quot;inside&quot; ... ## $ observedLength : num [1:91103] 62 62 109 154 113 120 147 70 74 86 ... ## $ survey : chr [1:91103] &quot;shock&quot; &quot;shock&quot; &quot;shock&quot; &quot;shock&quot; ... ## $ pass : num [1:91103] 1 1 1 1 1 1 1 1 1 1 ... ## $ observedWeight : num [1:91103] 1.9 2.7 12.6 41.3 15.5 18.3 30.4 3.5 4.8 6.7 ... ## $ comments : chr [1:91103] &quot;additional genetic sample&quot; NA NA NA ... ## $ cohort : num [1:91103] 2012 2012 2012 2012 2011 ... ## $ species : chr [1:91103] &quot;bkt&quot; &quot;bkt&quot; &quot;bkt&quot; &quot;bkt&quot; ... ## $ dateEmigrated : Date[1:91103], format: NA NA NA NA ... ## $ sex : chr [1:91103] NA NA NA NA ... ## $ year : num [1:91103] 2013 2012 2013 2013 2012 ... ## $ season : num [1:91103] 1 2 1 2 2 3 1 3 4 3 ... ## $ proportionSampled: num [1:91103] 1 1 1 1 1 1 1 1 1 1 ... ## $ lagDetectionDate : POSIXct[1:91103], format: NA NA &quot;2013-06-25 14:51:00&quot; NA ... ## $ meanTemperature : num [1:91103] NaN NaN 10.7 NaN 16.5 ... ## $ meanFlow : num [1:91103] NaN NaN 0.5247 NaN 0.0338 ... 2.2.2 Wrangle data This section takes cdWB_electro0 and cleans it to create cdWB_electro. reclean_cdWB_electro &lt;- FALSE if(reclean_cdWB_electro){ drainage &lt;- &#39;west&#39; # functions in getPrepareWBData library cdWB_electro &lt;- cdWB_electro0 %&gt;% cleanData(drainage) %&gt;% mergeSites(drainage) %&gt;% addNPasses(drainage) %&gt;% mutate(drainage = drainage) save(cdWB_electro, file = &#39;./data/cdWB_electro.RData&#39;) } else { load(file = &#39;./data/cdWB_electro.RData&#39;) } 2.2.3 Explore data ggplot(cdWB_electro, aes(observedLength, observedWeight, color = species)) + geom_point(alpha = 0.1) + scale_x_log10() + scale_y_log10() + theme_publication() + facet_wrap(~ species) lwReg &lt;- cdWB_electro %&gt;% nest_by(species) %&gt;% mutate(reg = list(lm(log(observedWeight) ~ log(observedLength), data = data))) lwReg %&gt;% summarise(broom::tidy(reg)) ## # A tibble: 6 x 6 ## # Groups: species [3] ## species term estimate std.error statistic p.value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ats (Intercept) -11.4 0.00942 -1210. 0 ## 2 ats log(observedLength) 3.00 0.00208 1442. 0 ## 3 bkt (Intercept) -11.5 0.00621 -1859. 0 ## 4 bkt log(observedLength) 3.02 0.00140 2155. 0 ## 5 bnt (Intercept) -11.5 0.00686 -1670. 0 ## 6 bnt log(observedLength) 3.01 0.00149 2023. 0 lwReg %&gt;% summarise(broom::glance(reg)) ## # A tibble: 3 x 13 ## # Groups: species [3] ## species r.squared adj.r.squared sigma statistic p.value df logLik AIC BIC deviance df.residual nobs ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 ats 0.989 0.989 0.0945 2080611. 0 1 22663. -45319. -45295. 215. 24092 24094 ## 2 bkt 0.991 0.991 0.112 4643341. 0 1 32555. -65105. -65079. 537. 42490 42492 ## 3 bnt 0.996 0.996 0.0858 4092957. 0 1 18345. -36683. -36660. 130. 17694 17696 2.3 Capture-recapture data getNew_encounterHistories &lt;- TRUE # maximum ageInSamples for both createCmrData and getEH maxAgeInSamples &lt;- 12 2.3.1 Temporary home for updated functions addEnvironmental &lt;- function(coreData, sampleFlow = F, funName = &quot;mean&quot;) { func &lt;- get(funName) whichDrainage &lt;- &quot;west&quot; if (all(!unique(coreData$river) %in% c(&quot;west brook&quot;, &quot;wb jimmy&quot;, &quot;wb mitchell&quot;, &quot;wb obear&quot;))) { whichDrainage &lt;- &quot;stanley&quot; } if (whichDrainage == &quot;west&quot;) { envData &lt;- tbl(conDplyr, &quot;data_daily_temperature&quot;) %&gt;% collect(n = Inf) %&gt;% full_join(tbl(conDplyr, &quot;data_flow_extension&quot;) %&gt;% collect(n = Inf), by = c(&quot;river&quot;, &quot;date&quot;)) %&gt;% dplyr::select(-source) %&gt;% dplyr::filter(date &lt;= max(coreData$detectionDate), date &gt;= min(coreData$detectionDate)) %&gt;% rename(temperature = daily_mean_temp, flow = qPredicted) %&gt;% data.frame() } else { envData &lt;- tbl(conDplyr, &quot;stanley_environmental&quot;) %&gt;% filter(section == 11) %&gt;% dplyr::select(datetime, temperature, depth) %&gt;% collect(n = Inf) %&gt;% rename(flow = depth, date = datetime) %&gt;% data.frame() warning(&quot;Depth was inserted into flow column because that is what is available in Stanley&quot;) } coreData &lt;- coreData %&gt;% group_by(tag) %&gt;% arrange(ageInSamples) %&gt;% mutate(lagDetectionDate = lead(detectionDate)) %&gt;% ungroup() if (whichDrainage == &quot;west&quot;) { getIntervalMean &lt;- function(start, end, r, e, fun = func) { d &lt;- envData$date if (e == &quot;Temperature&quot;) { envCol &lt;- &quot;temperature&quot; if (is.na(r)) meanVar &lt;- fun(envData[d &gt;= start &amp; d &lt;= end, envCol], na.rm = T) if (!is.na(r)) meanVar &lt;- fun(envData[d &gt;= start &amp; d &lt;= end &amp; envData$river == r, envCol], na.rm = T) } # will need to make this river-specific if (e == &quot;Flow&quot;) { envCol &lt;- &quot;flow&quot; meanVar &lt;- fun(envData[d &gt;= start &amp; d &lt;= end, envCol], na.rm = T) } return(meanVar) } coreDataUniqueDates &lt;- coreData %&gt;% dplyr::select(river, detectionDate, lagDetectionDate) %&gt;% unique() %&gt;% group_by(river, detectionDate, lagDetectionDate) %&gt;% mutate(meanTemperature = getIntervalMean(detectionDate, lagDetectionDate, river, &quot;Temperature&quot;), meanFlow = getIntervalMean(detectionDate, lagDetectionDate, river, &quot;Flow&quot;)) %&gt;% ungroup() coreData &lt;- left_join(coreData, coreDataUniqueDates, by = c(&quot;detectionDate&quot;, &quot;river&quot;, &quot;lagDetectionDate&quot;)) } else { getIntervalMean &lt;- function(start, end, e, fun = func) { d &lt;- envData$date meanEnv &lt;- fun(envData[d &gt;= start &amp; d &lt;= end, tolower(e)], na.rm = T) return(meanEnv) } coreDataUniqueDates &lt;- coreData %&gt;% dplyr::select(detectionDate, lagDetectionDate) %&gt;% unique() %&gt;% group_by(detectionDate, lagDetectionDate) %&gt;% mutate(meanTemperature = getIntervalMean(detectionDate, lagDetectionDate, &quot;Temperature&quot;), meanFlow = getIntervalMean(detectionDate, lagDetectionDate, &quot;Flow&quot;)) %&gt;% ungroup() coreData &lt;- left_join(coreData, coreDataUniqueDates, by = c(&quot;detectionDate&quot;, &quot;lagDetectionDate&quot;)) } if (sampleFlow) { coreData &lt;- coreData %&gt;% mutate(date = as.Date(detectionDate)) %&gt;% filter(enc == 1) %&gt;% dplyr::select(sampleName, date) %&gt;% group_by(sampleName, date) %&gt;% summarize(n = n()) %&gt;% ungroup() %&gt;% left_join(envData %&gt;% filter(!is.na(flow)) %&gt;% mutate(date = as.Date(date)) %&gt;% dplyr::select(date, flow) %&gt;% rename(flowForP = flow) %&gt;% unique(), by = c(&quot;date&quot;)) %&gt;% group_by(sampleName) %&gt;% summarize(flowForP = sum(flowForP * n)/(sum(n))) %&gt;% ungroup() %&gt;% right_join(coreData, by = &quot;sampleName&quot;) } names(coreData)[which(names(coreData) == &quot;meanTemperature&quot;)] &lt;- paste0(funName, &quot;Temperature&quot;) names(coreData)[which(names(coreData) == &quot;meanFlow&quot;)] &lt;- paste0(funName, &quot;Flow&quot;) return(coreData) } getKnown &lt;- function(x) { firstObs &lt;- min(which(x == 1)) lastObs &lt;- max(which(x == 1)) known &lt;- rep(0, length(x)) known[firstObs:lastObs] &lt;- 1 if (lastObs != length(known)) { known[(lastObs + 1):length(known)] &lt;- NA } return(known) } addKnownZ2 &lt;- function(d) { d %&gt;% group_by(tag) %&gt;% arrange(sampleNumber) %&gt;% mutate(knownZ = getKnown(enc)) %&gt;% ungroup() %&gt;% arrange(tag, sampleNumber) } addFirstLast &lt;- function(d){ firstLast &lt;- d %&gt;% group_by(tag) %&gt;% filter(knownZ == 1) %&gt;% summarize(firstObserved = min(sampleNumber, na.rm = TRUE), lastObserved = max(sampleNumber, na.rm = TRUE)) %&gt;% ungroup() left_join(d, firstLast) %&gt;% mutate(isFirstObserved = sampleNumber == firstObserved, isLastObserved = sampleNumber == lastObserved) } fillRiver &lt;- function (data, location = T){ fillLocation &lt;- function(location) { known &lt;- which(!is.na(location)) unknown &lt;- which(is.na(location)) nKnown &lt;- length(unique(location[known])) if (nKnown == 1) { location[unknown] &lt;- location[known[1]] } else { for (i in unknown) { location[i] &lt;- location[known[max(which(i &gt; known))]] } } return(location) } if (location) { data &lt;- data %&gt;% group_by(tag) %&gt;% mutate(river = fillLocation(river)) %&gt;% ungroup() } return(data) } scale_this &lt;- function(x){ (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE) } scaleEnvData &lt;- function(d){ tmp &lt;- d %&gt;% group_by(river, season) %&gt;% summarize(meanMeanFlow = mean(meanFlow, na.rm = TRUE), sdMeanFlow = sd(meanFlow, na.rm = TRUE), meanMeanTemperature = mean(meanTemperature, na.rm = TRUE), sdMeanTemperature = sd(meanTemperature, na.rm = TRUE) ) %&gt;% ungroup() out &lt;- left_join(d, tmp) %&gt;% mutate( meanFlowScaled = (meanFlow - meanMeanFlow) / sdMeanFlow, meanTemperatureScaled = (meanTemperature - meanMeanTemperature) / sdMeanTemperature ) } getNeverCaptured &lt;- function(d, maxOccasionValue){ d %&gt;% #filter(ageInSamples &gt; 0 &amp; ageInSamples &lt;= maxOccasionValue) %&gt;% filter(ageInSamples %in% 1:maxOccasionValue) %&gt;% group_by(tag) %&gt;% summarize(sumEnc = sum(enc, na.rm = TRUE)) %&gt;% filter(sumEnc == 0) %&gt;% dplyr::select(tag) } addRiverTagged &lt;- function(d){ d1 &lt;- d %&gt;% filter(isFirstObserved) %&gt;% mutate(riverTagged = river) %&gt;% dplyr::select(tag, riverTagged) return(left_join(d, d1)) } addIsYOY &lt;- function(d){ d %&gt;% mutate(isYOY = ifelse(ageInSamples &lt;= 3, 1, 2)) } `%notin%` &lt;- Negate(`%in%`) 2.3.2 Get data West Brook electrofishing data formatted for Capture-Mark-Recapture analysis for tagged individuals #source(&#39;./rForSourcing/envFunctions.R&#39;) if(getNew_cdWB_CMR0) { cdWB_CMR0 &lt;- createCoreData( sampleType = &quot;electrofishing&quot;, #&quot;stationaryAntenna&quot;,&quot;portableAntenna&quot;), whichDrainage = &quot;west&quot;, columnsToAdd = c(&quot;sampleNumber&quot;, &quot;river&quot;, &quot;riverMeter&quot;, &quot;survey&quot;, &quot;pass&quot;, &#39;observedLength&#39;, &#39;observedWeight&#39;) ) %&gt;% addTagProperties( columnsToAdd = c(&quot;cohort&quot;, &quot;species&quot;, &quot;dateEmigrated&quot;, &quot;sex&quot;, &quot;species&quot;) ) %&gt;% dplyr::filter(!is.na(tag), area %in% c(&quot;trib&quot;,&quot;inside&quot;,&quot;below&quot;,&quot;above&quot;), !is.na(sampleNumber) ) %&gt;% createCmrData(maxAgeInSamples = maxAgeInSamples + 1, # +1 so we get env data for the last interval inside = F, censorDead = F, censorEmigrated = F) %&gt;% # may want to change censorEmigrated = T to = F # sample 83 is the last tagging sample filter(sampleNumber &lt;= 83) %&gt;% addSampleProperties() %&gt;% addEnvironmental() %&gt;% # these functions do not work for CMR data - they separate out shock and non-shock samples #addEnvironmentalDaily() %&gt;% #addEnvironmentalInterval() %&gt;% addKnownZ2() %&gt;% addFirstLast() %&gt;% fillRiver() %&gt;% addRiverTagged() %&gt;% scaleEnvData() %&gt;% addIsYOY() save(cdWB_CMR0, file = &#39;./data/cdWB_CMR0.RData&#39;) #write.csv(cdWB_CMR0, file = &#39;./data/cdWB_CMR0.csv&#39;) } else { load(file = &#39;./data/cdWB_CMR0.RData&#39;) } str(cdWB_CMR0) ## tibble [321,788 × 38] (S3: tbl_df/tbl/data.frame) ## $ cohort : num [1:321788] 2012 2012 2012 2012 2012 ... ## $ tag : chr [1:321788] &quot;00088cbed0&quot; &quot;00088cbed0&quot; &quot;00088cbed0&quot; &quot;00088cbed0&quot; ... ## $ detectionDate : POSIXct[1:321788], format: &quot;2013-03-25 00:00:00&quot; &quot;2013-06-05 00:00:00&quot; &quot;2013-09-18 00:00:00&quot; &quot;2013-11-19 00:00:00&quot; ... ## $ sampleName : chr [1:321788] &quot;84&quot; &quot;85&quot; &quot;86&quot; &quot;87&quot; ... ## $ sampleNumber : num [1:321788] 73 74 75 76 77 78 79 80 81 82 ... ## $ river : chr [1:321788] &quot;wb obear&quot; &quot;wb obear&quot; &quot;wb obear&quot; &quot;wb obear&quot; ... ## $ section : chr [1:321788] &quot;7&quot; NA NA NA ... ## $ area : chr [1:321788] &quot;trib&quot; NA NA NA ... ## $ observedLength : num [1:321788] 62 NA NA NA NA NA NA NA NA NA ... ## $ survey : chr [1:321788] &quot;shock&quot; NA NA NA ... ## $ pass : num [1:321788] 1 NA NA NA NA NA NA NA NA NA ... ## $ observedWeight : num [1:321788] 1.9 NA NA NA NA NA NA NA NA NA ... ## $ species : chr [1:321788] &quot;bkt&quot; &quot;bkt&quot; &quot;bkt&quot; &quot;bkt&quot; ... ## $ dateEmigrated : Date[1:321788], format: NA NA NA NA ... ## $ sex : chr [1:321788] NA NA NA NA ... ## $ enc : num [1:321788] 1 0 0 0 0 0 0 0 0 0 ... ## $ ageInSamples : num [1:321788] 3 4 5 6 7 8 9 10 11 12 ... ## $ sampleIndex : num [1:321788] 63 64 65 66 67 68 69 70 71 72 ... ## $ tagIndex : num [1:321788] 1 1 1 1 1 1 1 1 1 1 ... ## $ year : num [1:321788] 2013 2013 2013 2013 2014 ... ## $ season : num [1:321788] 1 2 3 4 1 2 3 4 1 2 ... ## $ proportionSampled : num [1:321788] 1 NA NA NA NA NA NA NA NA NA ... ## $ lagDetectionDate : POSIXct[1:321788], format: &quot;2013-06-05 00:00:00&quot; &quot;2013-09-18 00:00:00&quot; &quot;2013-11-19 00:00:00&quot; &quot;2014-04-04 00:00:00&quot; ... ## $ meanTemperature : num [1:321788] 8.62 16.51 9.44 0.94 10.52 ... ## $ meanFlow : num [1:321788] 0.38874 0.30331 0.00882 0.31319 0.58363 ... ## $ knownZ : num [1:321788] 1 NA NA NA NA NA NA NA NA NA ... ## $ firstObserved : num [1:321788] 73 73 73 73 73 73 73 73 73 73 ... ## $ lastObserved : num [1:321788] 73 73 73 73 73 73 73 73 73 73 ... ## $ isFirstObserved : logi [1:321788] TRUE FALSE FALSE FALSE FALSE FALSE ... ## $ isLastObserved : logi [1:321788] TRUE FALSE FALSE FALSE FALSE FALSE ... ## $ riverTagged : chr [1:321788] &quot;wb obear&quot; &quot;wb obear&quot; &quot;wb obear&quot; &quot;wb obear&quot; ... ## $ meanMeanFlow : num [1:321788] 0.409 0.137 0.307 0.464 0.409 ... ## $ sdMeanFlow : num [1:321788] 0.155 0.126 0.246 0.113 0.155 ... ## $ meanMeanTemperature : num [1:321788] 10.39 16.23 8.42 1.65 10.39 ... ## $ sdMeanTemperature : num [1:321788] 1.202 0.711 1.455 0.616 1.202 ... ## $ meanFlowScaled : num [1:321788] -0.129 1.313 -1.215 -1.33 1.124 ... ## $ meanTemperatureScaled: num [1:321788] -1.472 0.402 0.7 -1.149 0.105 ... ## $ isYOY : num [1:321788] 1 2 2 2 2 2 2 2 2 2 ... 2.3.3 Make encounter history files # https://stackoverflow.com/questions/69583424/using-tidy-eval-for-multiple-arbitrary-filter-conditions # Assumes LHS is the name of a variable and OP is # the name of a function op_call &lt;- function(op, lhs, rhs) { call(op, sym(lhs), rhs) } ehFilter &lt;- function(data, cols, ops, vals) { exprs &lt;- purrr::pmap(list(ops, cols, vals), op_call) data %&gt;% dplyr::filter(!!!exprs) } # var is the variable to put in the encounter history (e.g. &#39;enc&#39; or &#39;temp&#39;) # occasionVar is now fixed to ageInSamples # maxOccasionValue is the maximum value for occasion columns, in units of &#39;occasionVar&#39; getEHDataWide_AIS &lt;- function(d, cols, ops, vals, var, maxOccasionValue, valuesFill = 0){ d %&gt;% ehFilter(cols, ops, vals) %&gt;% #filter(ageInSamples &gt; 0, ageInSamples &lt;= maxOccasionValue) %&gt;% arrange(ageInSamples) %&gt;% #need this to get correct order of columns. pivot_wider( id_cols = tag, names_from = ageInSamples, names_prefix = &quot;ais_&quot;, values_from = eval(substitute(var)), values_fill = valuesFill ) } getEH_AIS &lt;- function(dIn, cols, ops, vals, maxOccasionValue, maxIndexByCohort = 1E10){ d &lt;- dIn %&gt;% #filter(ageInSamples &gt; 0, ageInSamples &lt;= maxOccasionValue) filter(ageInSamples %in% 1:maxOccasionValue) # Fish with no observed occasions neverCaptured &lt;- getNeverCaptured(d, maxOccasionValue) d &lt;- d %&gt;% filter(tag %notin% neverCaptured$tag) # limit data to first &#39;maxIndexByCohort&#39; individuals for each cohort d &lt;- d %&gt;% group_by(cohort) %&gt;% mutate(indexByCohort = rleid(tag)) %&gt;% filter(indexByCohort &lt;= maxIndexByCohort) %&gt;% ungroup() encWide &lt;- getEHDataWide_AIS(d, cols, ops, vals, &quot;enc&quot;, maxOccasionValue, valuesFill = 0) eh &lt;- as.matrix(encWide %&gt;% dplyr::select(-tag), nrow = nrow(encWide), ncol = ncol(encWide) - 1) flowFill &lt;- 0 flowWide &lt;- getEHDataWide_AIS(d, cols, ops, vals, &quot;meanFlowScaled&quot;, maxOccasionValue, valuesFill = flowFill) flowMatrix &lt;- as.matrix(flowWide %&gt;% dplyr::select(-tag), nrow = nrow(flowWide), ncol = ncol(flowWide) - 1) flowMatrix &lt;- ifelse(is.finite(flowMatrix), flowMatrix, flowFill) temperatureFill &lt;- 0 temperatureWide &lt;- getEHDataWide_AIS(d, cols, ops, vals, &quot;meanTemperatureScaled&quot;, maxOccasionValue, valuesFill = temperatureFill) temperatureMatrix &lt;- as.matrix(temperatureWide %&gt;% dplyr::select(-tag), nrow = nrow(temperatureWide), ncol = ncol(temperatureWide) - 1) temperatureMatrix &lt;- ifelse(is.finite(temperatureMatrix), temperatureMatrix, temperatureFill) riverWide &lt;- getEHDataWide_AIS(d, cols, ops, vals, &quot;river&quot;, maxOccasionValue, valuesFill = &quot;none&quot;) riverMatrix &lt;- as.matrix(riverWide %&gt;% dplyr::select(-tag), nrow = nrow(riverWide), ncol = ncol(riverWide) - 1) isYOYWide &lt;- getEHDataWide_AIS(d, cols, ops, vals, &quot;isYOY&quot;, maxOccasionValue, valuesFill = 2) isYOYMatrix &lt;- as.matrix(isYOYWide %&gt;% dplyr::select(-tag), nrow = nrow(isYOYWide), ncol = ncol(riverWide) - 1) tags &lt;- encWide %&gt;% dplyr::select(tag) data &lt;- d %&gt;% ehFilter(cols, ops, vals) %&gt;% #filter(ageInSamples &gt; 0, ageInSamples &lt;= maxOccasionValue) %&gt;% filter(ageInSamples %in% 1:maxOccasionValue) %&gt;% arrange(tag, ageInSamples) cohorts &lt;- tags %&gt;% left_join(data %&gt;% dplyr::select(tag, cohort) %&gt;% unique()) %&gt;% dplyr::select(cohort) seasons &lt;- tags %&gt;% left_join(data %&gt;% dplyr::select(tag, season) %&gt;% unique()) %&gt;% dplyr::select(season) first &lt;- apply(eh, 1, function(x) min(which(x != 0))) last &lt;- apply(riverMatrix, 1, function(x) max(which(!is.na(x)))) last &lt;- ifelse(last == maxOccasionValue, last, last - 1) return(list(eh = eh, flow = flowMatrix, temperature = temperatureMatrix, river = riverMatrix, isYOY = isYOYMatrix, tags = tags, cohorts = cohorts, seasons = seasons, first = first, last = last, data = data)) } #if (getNew_encounterHistories) { # read down through the cols, ops, vals variables for filter conditions # all cohorts 2002:2014 cdWB_CMR0 %&gt;% filter(river == &quot;wb obear&quot;) %&gt;% group_by(cohort) %&gt;% summarize(n = n()) ## # A tibble: 17 × 2 ## cohort n ## &lt;dbl&gt; &lt;int&gt; ## 1 1999 2 ## 2 2000 135 ## 3 2001 1285 ## 4 2002 2358 ## 5 2003 3009 ## 6 2004 1844 ## 7 2005 791 ## 8 2006 1443 ## 9 2007 1058 ## 10 2008 968 ## 11 2009 5580 ## 12 2010 499 ## 13 2011 444 ## 14 2012 6246 ## 15 2013 729 ## 16 2014 725 ## 17 2015 5 cols &lt;- list(&quot;cohort&quot;, &quot;riverTagged&quot;) ops &lt;- list(&quot;%in%&quot;, &quot;==&quot;) vals &lt;- list(2002:2014, &quot;wb obear&quot;) # only include first x fish per cohort eh &lt;- getEH_AIS(cdWB_CMR0, cols, ops, vals, maxAgeInSamples)#, maxIndexByCohort = 100) fileName = paste0(&quot;eh_&quot;, stri_paste_list(vals, collapse = &quot;_&quot;)) save(eh, file = paste0(&#39;./models/cmrFlowWB/dataOut/&#39;, fileName, &#39;.RData&#39;)) # output for Xioawei for (i in seq_along(eh)){ write.csv(eh[[i]], file = paste0(&#39;./models/cmrFlowWB/dataOut/&#39;, names(eh)[i], &quot;.csv&quot;), row.names = F) } #} 2.3.4 Wrangle data 2.3.5 Explore data ggplot(cdWB_CMR0 %&gt;% filter(enc ==1), aes(year)) + geom_bar() + facet_grid(river + season ~ species) 2.3.6 CMR metadata 2.3.6.1 adapted from https://github.com/Conte-Ecology/westBrookData/blob/master/getWBData/vignettes/westBrookDataIntro.Rmd 2.3.6.2 Column explanations tag PIT tag number, unique identifier, character cohort year the fish was born, assigned based on size at initial capture and size distributions of fish of known age detectionDate mostly self explanatory, but filled in for unobserved fish as the median capture date for all observed fish. sampleName An ordered identifier for sampling mostly for recognition by people who did the sampling. This is not very clean because early in the study samples were not taken at strictly seasonal intervals. sampleNumber is probably more useful and intuitive. sampleNumber A tidier identifier for samples that strictly increases by one for each season (4/yr) river River the fish was observed in. NA if the fish was not observed. west brook The mainstem wb jimmy Larger tributary that fish can move back and forth into from WB section 31 (Open Large from Letcher et al 2015) wb mitchell Smaller tributary that fish can move back and forth into from WB section 35 (Open Small from Letcher et al 2015) wb obear Smaller tributary that has a waterfall at its mouth, so fish can only move downstream into WB section 20 (Isolated Small from Letcher et al 2015) section Identifier for the 20m section that the fish was captured in. This is ordered from downstream to upstream starting at 1 within each river. area inside = section 1:47 in the west brook, trib = tributary (not west brook), below = sections below inside sections, above = sections above the inside sections observedLength in mm survey shock = electroshocking survey pass electrofishing pass. 1 or 2 in the west brook (inside), 1 in tribs observedWeight in g wet weight species bkt = brook trout (native, self-sustained population) bnt = brown trout (non-native, self-sustained population) ats = atlantic salmon (stocked through 2005, no reproduction) dateEmigrated date of emigration from inside/tribs if observed to emigrate. Coded as emigrated if last observation was on PIT antenna or captured below or above sex NA = unknown, f = female, m = male, p = precocious male (salmon only) enc Logical, was the fish observed? (1 = yes, 0 = no) ageInSamples number of seasons since summer of the year of birth (1st summer = 0) sampleIndex sampleNumber rescaled to start at 1 and end at length(unique(sampleNumber)) for ease of looping in JAGS tagIndex ordered, unique individual identifier 1:N year of sample season 1 = spring, 2 = summer, 3 = fall, 4 = winter proportionSampled Occasionally the sample was not complete (e.g., skipped west brook but did the tributaries). This is the proportion of sections in the river of capture that were sampled. lagDetectionDate detection date lagged back one observation meanTemperature mean temperature between observation dates. If individual was not observed, median observation date for the sampling occasion was used. meanFlow mean flow between observation dates. If individual was not observed, median observation date for the sampling occasion was used. knownZ z is alive state, so this is ‘1’ between first and last capture, and NA otherwise, unless the fish was known to be dead (e.g. tagging mortality or observed dead) in which case the value is set to ‘2’. There is also an option in the addKnownZ() function to useAntenna. This is useAntenna = FALSE by default, but could be set to TRUE to set knownZ to 1 up to the last antenna observation. 2.4 Wanding data 2.4.1 Get data West Brook wanding data if(getNew_cdWB_wanding0) { # from wandingDataWB project in d:/ben/github/wandingData/ cdWB_wanding0 &lt;- createCoreData( sampleType = &quot;portableAntenna&quot;, columnsToAdd = c(&quot;tag&quot;, &quot;detectionDate&quot;, &quot;river&quot;, &quot;area&quot;, &quot;section&quot;, &quot;survey&quot;, &quot;sampleName&quot;, &quot;readerId&quot;, &quot;aliveOrDead&quot;, &quot;instance&quot;, &quot;pass&quot;, &quot;quarter&quot;, &quot;leftOrRight&quot;, &quot;habitat&quot;, &quot;cover&quot;, &quot;justification&quot;, &quot;comment&quot;) ) %&gt;% addTagProperties() %&gt;% dplyr::filter( species %in% c( &quot;bkt&quot;,&quot;bnt&quot;,&quot;ats&quot; ) ) save(cdWB_wanding0, file = &#39;./data/cdWB_wanding0.RData&#39;) } else { load(file = &#39;./data/cdWB_wanding0.RData&#39;) } str(cdWB_wanding0) ## tibble [14,880 × 19] (S3: tbl_df/tbl/data.frame) ## $ tag : chr [1:14880] &quot;00088cf41b&quot; &quot;00088cf41b&quot; &quot;00088cf41b&quot; &quot;00088cf435&quot; ... ## $ detectionDate: POSIXct[1:14880], format: &quot;2010-09-27 11:08:45&quot; &quot;2010-10-18 14:16:22&quot; &quot;2010-10-25 11:40:24&quot; &quot;2010-12-06 13:32:15&quot; ... ## $ sampleName : chr [1:14880] &quot;92710.00&quot; &quot;101810.00&quot; &quot;102510.00&quot; &quot;12610.00&quot; ... ## $ river : chr [1:14880] &quot;wb jimmy&quot; &quot;wb jimmy&quot; &quot;wb jimmy&quot; &quot;wb jimmy&quot; ... ## $ section : chr [1:14880] &quot;13&quot; &quot;14&quot; &quot;14&quot; &quot;2&quot; ... ## $ area : chr [1:14880] &quot;trib&quot; &quot;trib&quot; &quot;trib&quot; &quot;trib&quot; ... ## $ survey : chr [1:14880] &quot;portableAntenna&quot; &quot;portableAntenna&quot; &quot;portableAntenna&quot; &quot;portableAntenna&quot; ... ## $ readerId : chr [1:14880] &quot;iso&quot; &quot;iso&quot; &quot;iso&quot; &quot;iso&quot; ... ## $ aliveOrDead : chr [1:14880] &quot;alive&quot; &quot;alive&quot; NA &quot;alive&quot; ... ## $ instance : num [1:14880] 1 2 3 1 1 1 2 1 1 1 ... ## $ pass : num [1:14880] NA NA NA NA NA NA NA NA NA NA ... ## $ quarter : num [1:14880] 2 1 NA 4 2 4 4 3 4 2 ... ## $ leftOrRight : chr [1:14880] &quot;l&quot; &quot;m&quot; NA &quot;r&quot; ... ## $ habitat : chr [1:14880] &quot;pool&quot; &quot;run&quot; NA &quot;pool&quot; ... ## $ cover : chr [1:14880] NA NA NA NA ... ## $ justification: chr [1:14880] NA NA NA NA ... ## $ comment : chr [1:14880] NA NA NA NA ... ## $ species : chr [1:14880] &quot;bkt&quot; &quot;bkt&quot; &quot;bkt&quot; &quot;bkt&quot; ... ## $ cohort : num [1:14880] 2010 2010 2010 2010 2009 ... 2.4.2 Wrangle data 2.4.3 Explore data 2.5 Antenna data 2.5.1 Get data West Brook antenna data Note: some pitAntenna code at https://github.com/bletcher/pitAntenna/blob/master/WB/getAndPrepareDataWB.R if(getNew_cdWB_antenna0) { cdWB_antenna0 &lt;- createCoreData( sampleType=c(&quot;stationaryAntenna&quot;), whichDrainage = &quot;west&quot;, columnsToAdd=c( &quot;river&quot;, &quot;riverMeter&quot;, &quot;survey&quot;, &quot;readerID&quot;, &quot;comment&quot; ) ) %&gt;% filter(!is.na(tag)) %&gt;% # for now addTagProperties(columnsToAdd = c( &quot;cohort&quot;, &quot;species&quot;, &quot;dateEmigrated&quot;, &quot;sex&quot;, &quot;species&quot;) ) save(cdWB_antenna0, file = &#39;./data/cdWB_antenna0.RData&#39;) } else { load(file = &#39;./data/cdWB_antenna0.RData&#39;) } str(cdWB_antenna0) ## tibble [410,915 × 10] (S3: tbl_df/tbl/data.frame) ## $ tag : chr [1:410915] &quot;00088cbed9&quot; &quot;00088cbed9&quot; &quot;00088cbed9&quot; &quot;00088cbed9&quot; ... ## $ detectionDate: POSIXct[1:410915], format: &quot;2014-10-17 20:22:33&quot; &quot;2014-10-24 15:34:31&quot; &quot;2014-10-24 16:03:51&quot; &quot;2014-10-24 17:29:37&quot; ... ## $ river : chr [1:410915] &quot;wb mitchell&quot; &quot;wb mitchell&quot; &quot;wb mitchell&quot; &quot;wb mitchell&quot; ... ## $ riverMeter : num [1:410915] 4797 4797 4830 4830 5524 ... ## $ survey : chr [1:410915] &quot;stationaryAntenna&quot; &quot;stationaryAntenna&quot; &quot;stationaryAntenna&quot; &quot;stationaryAntenna&quot; ... ## $ comment : chr [1:410915] NA NA NA NA ... ## $ cohort : num [1:410915] 2013 2013 2013 2013 2013 ... ## $ species : chr [1:410915] &quot;bkt&quot; &quot;bkt&quot; &quot;bkt&quot; &quot;bkt&quot; ... ## $ dateEmigrated: Date[1:410915], format: &quot;2014-10-25&quot; &quot;2014-10-25&quot; &quot;2014-10-25&quot; &quot;2014-10-25&quot; ... ## $ sex : chr [1:410915] NA NA NA NA ... 2.5.2 Wrangle data 2.5.3 Explore data "],["models.html", "Chapter 3 Models 3.1 Young-of-year size model 3.2 Flow model 3.3 Flow effects on survival (phi) models", " Chapter 3 Models List of models will go here 3.1 Young-of-year size model The question here is what is driving body size variation across years in brook trout and brown trout in the WB? We focus on ageInSamples == 1 (age-0 fish in the fall sample) fish for growth model. This is the first sampling occasion that most fish are big enough to tag. Not all fish are big enough, however, and there is a number of untagged fish each year. We need to include both tagged and untagged fish in our age-0 size model. Factors to include in the model are 1. Sample date 2. Cumulative temperature prior to sampling 3. Cumulative flow prior to sampling 4. Extreme flow events?? Floods, droughts? 5. Fish density, age-0 counts across all three salmonids 3.1.1 Raw data for YOY model Environmental data (flow, temperature) are from 1, 3, or 5 months prior to date of individual capture. Also can used fixed dates: assumed spawning dates, assumed emergence dates and actual observation (sample) dates. All fish data are from age-0 in autumn. Abundance data. 3.1.2 Get environmental data West Brook environmental data (flow and temperature) load(file = &#39;./data/envDataWB.RData&#39;) 3.1.3 Get first observations Filter cdWB_electro for first observations in the autumn for age-0 fish (ageInsamples == 1). Including both tagged and untagged fish. selectedVariables &lt;- c(&quot;tag&quot;, &quot;species&quot;, &quot;river&quot;, &quot;detectionDate&quot;, &quot;sampleNumber&quot;, &quot;n&quot;, &quot;proportionSampled&quot;, &quot;observedLength&quot;, &quot;observedWeight&quot;, &quot;area&quot;, &quot;section&quot;, &quot;season&quot;, &quot;isYOY&quot;) firstObs_noTag &lt;- cdWB_electro %&gt;% filter(is.na(tag), ageInSamples == 1) %&gt;% mutate(n = 1) %&gt;% dplyr:: select(all_of(selectedVariables)) firstObs_tag &lt;- cdWB_electro %&gt;% group_by(tag) %&gt;% mutate(isFirstObs = detectionDate == min(detectionDate), n = n()) %&gt;% filter(isFirstObs, ageInSamples == 1) %&gt;% dplyr::select(all_of(selectedVariables)) %&gt;% ungroup() firstObs0 &lt;- add_row(firstObs_tag, firstObs_noTag) %&gt;% mutate(date = as_date(detectionDate), yday = yday(date), year = year(date)) For each date in firstObs0 that at least one fish was captured, calculate summary stats for flow and temperature for different time periods: 1. Assumed spawning to capture 2. Assumed spawning to assumed emergence 3. Assumed emergence to capture 4. One month preceding capture 5. Three months preceding capture 5. Five months preceding capture Then merge results with firstObs0 to create firstObs. spawn_month &lt;- &quot;11&quot; # spawning spawn_day &lt;- &quot;15&quot; emerge_month &lt;- &quot;03&quot; # emergence emerge_day &lt;- &quot;01&quot; firstObsDates &lt;- firstObs0 %&gt;% distinct(date = date(detectionDate), river) # move to getPrepareWBData getEnvMeans &lt;- function(riverIn, start, end) { out &lt;- envDataWB %&gt;% filter(river == riverIn, dateDate &gt;= start, dateDate &lt;= end) %&gt;% summarize( sumT = sum(temperature, na.rm = TRUE), meanT = mean(temperature, na.rm = TRUE), sdT = sd(temperature, na.rm = TRUE), cvT = sdT/meanT, sumF = sum(flow, na.rm = TRUE), meanF = mean(flow, na.rm = TRUE), sdF = sd(flow, na.rm = TRUE), cvF = sdF/meanF, n = n() ) #message(paste(river, start, end,tag)) return(out) } firstObs_Env &lt;- firstObsDates %&gt;% rowwise() %&gt;% mutate( year = year(date), spawnDate = ymd(paste0(year,spawn_month,spawn_day)) - years(1), emergeDate = ymd(paste0(year,emerge_month,emerge_day)), oneMonthDate = date - days(as.integer(1 * 30.5)), #months(1), &#39;months gives error when prev month has 30 days and current has 31 threeMonthDate = date - days(as.integer(3 * 30.5)), fiveMonthDate = date - days(as.integer(5 * 30.5)), spawn_emerge = list(getEnvMeans(river, spawnDate, emergeDate)), emerge_detect = list(getEnvMeans(river, emergeDate, date)), spawn_detect = list(getEnvMeans(river, spawnDate, date)), oneMonth = list(getEnvMeans(river, oneMonthDate, date)), threeMonth = list(getEnvMeans(river, threeMonthDate, date)), fiveMonth = list(getEnvMeans(river, fiveMonthDate, date)) ) # merge env data into firstObs0 firstObs &lt;- firstObs0 %&gt;% left_join(firstObs_Env) #str(firstObs) Unnest firstObs so environmental summary stats are available as data frame with the name of the time interval as the prefix to the statisticVariable name getScaled &lt;- function(d){ (d - mean(d, na.rm = TRUE)) / sd(d, na.rm = TRUE) } # this scales across all individuals - I think this is ok firstObsUnnested &lt;- firstObs %&gt;% unnest(cols = c(spawn_emerge, emerge_detect, spawn_detect, oneMonth, threeMonth, fiveMonth), names_sep = &quot;_&quot;) %&gt;% mutate( emerge_detect_sumTScaled = getScaled(emerge_detect_sumT), emerge_detect_sumFScaled = getScaled(emerge_detect_sumF), oneMonth_sumTScaled = getScaled(oneMonth_sumT), oneMonth_sumFScaled = getScaled(oneMonth_sumF), threeMonth_sumTScaled = getScaled(threeMonth_sumT), threeMonth_sumFScaled = getScaled(threeMonth_sumF), fiveMonth_sumTScaled = getScaled(fiveMonth_sumT), fiveMonth_sumFScaled = getScaled(fiveMonth_sumF), ydayScaled = getScaled(yday) ) str(firstObsUnnested) ## tibble [20,783 × 84] (S3: tbl_df/tbl/data.frame) ## $ tag : chr [1:20783] &quot;00088cbed7&quot; &quot;00088cbed8&quot; &quot;00088cbedb&quot; &quot;00088cbedd&quot; ... ## $ species : chr [1:20783] &quot;bkt&quot; &quot;bnt&quot; &quot;bkt&quot; &quot;bkt&quot; ... ## $ river : chr [1:20783] &quot;wb obear&quot; &quot;west brook&quot; &quot;west brook&quot; &quot;wb obear&quot; ... ## $ detectionDate : POSIXct[1:20783], format: &quot;2014-09-17 00:00:00&quot; &quot;2012-09-26 11:01:00&quot; &quot;2014-09-24 11:45:00&quot; &quot;2012-09-21 00:00:00&quot; ... ## $ sampleNumber : num [1:20783] 79 71 79 71 79 71 71 79 71 79 ... ## $ n : num [1:20783] 2 3 1 3 1 1 4 2 1 1 ... ## $ proportionSampled : num [1:20783] 1 1 1 1 1 1 1 1 1 1 ... ## $ observedLength : num [1:20783] 70 86 89 61 60 64 70 62 87 73 ... ## $ observedWeight : num [1:20783] 3.5 6.7 8.3 2.4 2.4 2.8 4.6 2.3 7.5 4.2 ... ## $ area : chr [1:20783] &quot;trib&quot; &quot;inside&quot; &quot;inside&quot; &quot;trib&quot; ... ## $ section : num [1:20783] 3 23 30 8 42 20 5 11 27 3 ... ## $ season : num [1:20783] 3 3 3 3 3 3 3 3 3 3 ... ## $ isYOY : logi [1:20783] TRUE TRUE TRUE TRUE TRUE TRUE ... ## $ date : Date[1:20783], format: &quot;2014-09-17&quot; &quot;2012-09-26&quot; &quot;2014-09-24&quot; &quot;2012-09-21&quot; ... ## $ yday : int [1:20783] 260 270 267 265 269 270 264 260 270 258 ... ## $ year : int [1:20783] 2014 2012 2014 2012 2014 2012 2012 2014 2012 2014 ... ## $ spawnDate : Date[1:20783], format: &quot;2013-11-15&quot; &quot;2011-11-15&quot; &quot;2013-11-15&quot; &quot;2011-11-15&quot; ... ## $ emergeDate : Date[1:20783], format: &quot;2014-03-01&quot; &quot;2012-03-01&quot; &quot;2014-03-01&quot; &quot;2012-03-01&quot; ... ## $ oneMonthDate : Date[1:20783], format: &quot;2014-08-18&quot; &quot;2012-08-27&quot; &quot;2014-08-25&quot; &quot;2012-08-22&quot; ... ## $ threeMonthDate : Date[1:20783], format: &quot;2014-06-18&quot; &quot;2012-06-27&quot; &quot;2014-06-25&quot; &quot;2012-06-22&quot; ... ## $ fiveMonthDate : Date[1:20783], format: &quot;2014-04-18&quot; &quot;2012-04-27&quot; &quot;2014-04-25&quot; &quot;2012-04-22&quot; ... ## $ spawn_emerge_sumT : num [1:20783] 110 358 131 313 131 ... ## $ spawn_emerge_meanT : num [1:20783] 1.03 3.32 1.22 2.9 1.22 ... ## $ spawn_emerge_sdT : num [1:20783] 1.36 2.3 1.56 2.43 1.56 ... ## $ spawn_emerge_cvT : num [1:20783] 1.321 0.695 1.274 0.838 1.274 ... ## $ spawn_emerge_sumF : num [1:20783] 0 48.7 25.7 0 25.7 ... ## $ spawn_emerge_meanF : num [1:20783] NaN 0.451 0.24 NaN 0.24 ... ## $ spawn_emerge_sdF : num [1:20783] NA 0.457 0.352 NA 0.352 ... ## $ spawn_emerge_cvF : num [1:20783] NA 1.01 1.47 NA 1.47 ... ## $ spawn_emerge_n : int [1:20783] 107 108 107 108 107 108 108 107 108 107 ... ## $ emerge_detect_sumT : num [1:20783] 2191 2791 2597 2602 2622 ... ## $ emerge_detect_meanT : num [1:20783] 10.9 13.3 12.5 12.7 12.5 ... ## $ emerge_detect_sdT : num [1:20783] 5.74 4.82 6.36 5 6.33 ... ## $ emerge_detect_cvT : num [1:20783] 0.527 0.362 0.51 0.394 0.507 ... ## $ emerge_detect_sumF : num [1:20783] 0 28.6 71.6 0 71.6 ... ## $ emerge_detect_meanF : num [1:20783] NaN 0.136 0.344 NaN 0.341 ... ## $ emerge_detect_sdF : num [1:20783] NA 0.246 0.533 NA 0.532 ... ## $ emerge_detect_cvF : num [1:20783] NA 1.81 1.55 NA 1.56 ... ## $ emerge_detect_n : int [1:20783] 201 210 208 205 210 210 204 201 210 199 ... ## $ spawn_detect_sumT : num [1:20783] 2301 3149 2728 2915 2753 ... ## $ spawn_detect_meanT : num [1:20783] 7.5 9.93 8.69 9.34 8.71 ... ## $ spawn_detect_sdT : num [1:20783] 6.65 6.27 7.48 6.32 7.46 ... ## $ spawn_detect_cvT : num [1:20783] 0.887 0.631 0.861 0.677 0.857 ... ## $ spawn_detect_sumF : num [1:20783] 0 77.1 97.2 0 97.2 ... ## $ spawn_detect_meanF : num [1:20783] NaN 0.243 0.31 NaN 0.307 ... ## $ spawn_detect_sdF : num [1:20783] NA 0.365 0.482 NA 0.481 ... ## $ spawn_detect_cvF : num [1:20783] NA 1.5 1.56 NA 1.57 ... ## $ spawn_detect_n : int [1:20783] 307 317 314 312 316 317 311 307 317 305 ... ## $ oneMonth_sumT : num [1:20783] 470 461 454 489 445 ... ## $ oneMonth_meanT : num [1:20783] 15.2 14.9 14.6 15.8 14.4 ... ## $ oneMonth_sdT : num [1:20783] 1.69 1.89 2.45 1.7 2.44 ... ## $ oneMonth_cvT : num [1:20783] 0.112 0.127 0.167 0.108 0.17 ... ## $ oneMonth_sumF : num [1:20783] 0 2.1101 -0.0766 0 -0.2195 ... ## $ oneMonth_meanF : num [1:20783] NaN 0.06807 -0.00247 NaN -0.00708 ... ## $ oneMonth_sdF : num [1:20783] NA 0.3031 0.0204 NA 0.0176 ... ## $ oneMonth_cvF : num [1:20783] NA 4.45 -8.24 NA -2.48 ... ## $ oneMonth_n : int [1:20783] 31 31 31 31 31 31 31 31 31 31 ... ## $ threeMonth_sumT : num [1:20783] 1445 1523 1571 1559 1561 ... ## $ threeMonth_meanT : num [1:20783] 15.7 16.6 17.1 16.9 17 ... ## $ threeMonth_sdT : num [1:20783] 1.35 1.8 2.5 1.59 2.59 ... ## $ threeMonth_cvT : num [1:20783] 0.0859 0.1085 0.1463 0.0936 0.1526 ... ## $ threeMonth_sumF : num [1:20783] 0 1.17 12.25 0 11.8 ... ## $ threeMonth_meanF : num [1:20783] NaN 0.0127 0.1331 NaN 0.1283 ... ## $ threeMonth_sdF : num [1:20783] NA 0.184 0.298 NA 0.298 ... ## $ threeMonth_cvF : num [1:20783] NA 14.52 2.24 NA 2.32 ... ## $ threeMonth_n : int [1:20783] 92 92 92 92 92 92 92 92 92 92 ... ## $ fiveMonth_sumT : num [1:20783] 2086 2400 2425 2281 2432 ... ## $ fiveMonth_meanT : num [1:20783] 13.6 15.7 15.8 14.9 15.9 ... ## $ fiveMonth_sdT : num [1:20783] 3.16 2.54 3.07 3.2 2.98 ... ## $ fiveMonth_cvT : num [1:20783] 0.232 0.162 0.194 0.215 0.188 ... ## $ fiveMonth_sumF : num [1:20783] 0 16.9 39.3 0 38.3 ... ## $ fiveMonth_meanF : num [1:20783] NaN 0.111 0.257 NaN 0.251 ... ## $ fiveMonth_sdF : num [1:20783] NA 0.246 0.427 NA 0.427 ... ## $ fiveMonth_cvF : num [1:20783] NA 2.23 1.66 NA 1.7 ... ## $ fiveMonth_n : int [1:20783] 153 153 153 153 153 153 153 153 153 153 ... ## $ emerge_detect_sumTScaled: num [1:20783] -0.261 1.215 0.738 0.751 0.799 ... ## $ emerge_detect_sumFScaled: num [1:20783] -1.346 -0.518 0.727 -1.346 0.725 ... ## $ oneMonth_sumTScaled : num [1:20783] 0.3199 0.1864 0.085 0.5805 -0.0332 ... ## $ oneMonth_sumFScaled : num [1:20783] -0.329 0.206 -0.348 -0.329 -0.384 ... ## $ threeMonth_sumTScaled : num [1:20783] 0.275 0.523 0.676 0.638 0.644 ... ## $ threeMonth_sumFScaled : num [1:20783] -0.798 -0.671 0.536 -0.798 0.488 ... ## $ fiveMonth_sumTScaled : num [1:20783] -0.0187 0.8552 0.9245 0.5252 0.9456 ... ## $ fiveMonth_sumFScaled : num [1:20783] -1.261 -0.376 0.796 -1.261 0.745 ... ## $ ydayScaled : num [1:20783] -0.6678 0.3131 0.0189 -0.1773 0.215 ... #ggplot(firstObsUnnested, aes(oneMonth_sumTScaled, fiveMonth_sumTScaled)) + # geom_point() + # facet_wrap(~river) 3.1.4 Counts of captured fish Min and max years (inclusive) for standardizing counts minYear &lt;- 2000 maxYear &lt;- 2015 Counts by river and species countsRSY &lt;- firstObs %&gt;% filter(year %in% minYear:maxYear) %&gt;% group_by(river, species, year) %&gt;% summarize( count = n(), meanPropSampled = mean(proportionSampled, na.rm = TRUE) ) %&gt;% mutate(countAdj = count / meanPropSampled) %&gt;% ungroup() %&gt;% group_by(river, species) %&gt;% mutate(meanCountRS = mean(count, na.rm = TRUE), sdCountRS = sd(count, na.rm = TRUE), countRS_Scaled = (count - meanCountRS) / sdCountRS) %&gt;% ungroup() ggplot(countsRSY, aes(year, countRS_Scaled, color = species)) + geom_point() + geom_line() + facet_wrap(~ river) Counts by river countsRY &lt;- firstObs %&gt;% filter(year %in% minYear:maxYear) %&gt;% group_by(river, year) %&gt;% summarize( count = n(), meanPropSampled = mean(proportionSampled, na.rm = TRUE) ) %&gt;% mutate(countAdj = count / meanPropSampled) %&gt;% ungroup() %&gt;% group_by(river) %&gt;% mutate(meanCountR = mean(count, na.rm = TRUE), sdCountR = sd(count, na.rm = TRUE), countR_Scaled = (count - meanCountR) / sdCountR) %&gt;% ungroup() ggplot(countsRY, aes(year, countR_Scaled, color = river)) + geom_point() + geom_line() Counts for the metaPopulation (WB, Jimmy, Mitchell) Use these for modelling. countsMetaY &lt;- firstObs %&gt;% filter(river != &quot;wb obear&quot;, year %in% minYear:maxYear) %&gt;% group_by(year) %&gt;% summarize( count = n(), meanPropSampled = mean(proportionSampled, na.rm = TRUE) ) %&gt;% mutate(countAdj = count / meanPropSampled) %&gt;% ungroup() %&gt;% mutate(meanCount = mean(count, na.rm = TRUE), sdCount = sd(count, na.rm = TRUE), count_Scaled = (count - meanCount) / sdCount) # missing data for tribs in 2000, 2001 - may skew scaled count a bit low - should fix ggplot(countsMetaY, aes(year, count_Scaled)) + geom_point() + geom_line() Merge metapopulation scaled counts into firstObsUnnested firstObsUnnested &lt;- firstObsUnnested %&gt;% left_join(countsMetaY %&gt;% dplyr::select(year, count_Scaled)) firstObsUnnestedWB &lt;- firstObsUnnested %&gt;% filter(river == &quot;west brook&quot;) 3.1.5 Raw data plots 3.1.5.1 Frequency plots by species and river 3.1.5.2 Brook Trout, West brook #cd1 &lt;- cdWB_electro %&gt;% filter(ageInSamples == 1, species != &#39;ats&#39;) plotSppRiv = function(s, r) { ggplot(firstObs %&gt;% filter(species == s, river == r), aes(observedLength, color = is.na(tag))) + geom_freqpoly() + geom_vline(xintercept = 60) + ggtitle(paste(s, r, sep = &#39;, &#39;)) + xlim(c(30,125)) + facet_wrap(~ year, scales = &quot;free_y&quot;) } species = &#39;bkt&#39; riverOrdered = &quot;west brook&quot; plotSppRiv(species, riverOrdered) 3.1.5.3 Brook Trout, wb jimmy 3.1.5.4 Brook Trout, wb mitchell 3.1.5.5 Brook Trout, wb obear 3.1.5.6 Brown Trout, West brook 3.1.5.7 Brown Trout, wb jimmy 3.1.5.8 Brown Trout, wb mitchell 3.1.5.9 Brown Trout, wb obear - there are no Brown trout in O’Bear 3.1.5.10 Trout, in the WB mainstem only ggplot(firstObs %&gt;% filter(species != &quot;ats&quot;), aes(observedLength)) + geom_freqpoly() + geom_vline(xintercept = 60, color = &#39;orange&#39;) + facet_grid(species ~ year) ggplot(firstObs %&gt;% filter(species != &quot;ats&quot;), aes(observedLength, color = is.na(tag))) + geom_freqpoly() + geom_vline(xintercept = 60, color = &#39;orange&#39;) + facet_grid(species ~ year) 3.1.5.11 Why are there untagged fish bigger than 60mm? Check 2002/bkt/WB, as an example Answer: because they are outside the study area (area = ‘above’ or ‘below’) or were tagging mortalities firstObs2002BKT &lt;- firstObs %&gt;% filter(year == 2002, species == &quot;bkt&quot;) table(is.na(firstObs2002BKT$tag)) ## ## FALSE TRUE ## 295 253 ggplot(firstObs2002BKT, aes(observedLength, color = is.na(tag))) + geom_freqpoly() + geom_vline(xintercept = 60) # looks like untagged area=inside fish wee morts, the rest were above or below ggplot(firstObs2002BKT, aes(observedLength, color = is.na(tag))) + geom_freqpoly() + geom_vline(xintercept = 60) + facet_grid(~area) # check 2003 ggplot(firstObs %&gt;% filter(year == 2003, species == &quot;bkt&quot;), aes(observedLength, color = is.na(tag))) + geom_freqpoly() + geom_vline(xintercept = 60) + facet_grid(~area) # same story as 2002 3.1.5.12 Why no untagged fish for 2000 and 2001? Check data logs to see if we were not recording untagged fish in 2000, 2001 cfirstObs2000_2001BKT &lt;- firstObs %&gt;% filter(year %in% 2000:2001, species == &quot;bkt&quot;) table(is.na(cfirstObs2000_2001BKT$tag)) ## ## FALSE ## 343 table(cfirstObs2000_2001BKT$observedLength) ## ## 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 85 90 ## 18 23 23 26 20 28 19 14 28 23 20 21 9 14 8 11 3 8 4 5 6 5 1 3 2 1 cfirstObs2000_2001BKT %&gt;% filter(observedLength &lt; 60) ## # A tibble: 64 × 27 ## tag species river detectionDate sampleNumber n proportionSampl… observedLength observedWeight area ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1bf0fc3a19 bkt west… 2001-09-10 12:00:00 27 2 1 58 1.9 insi… ## 2 1bf0fc46b1 bkt west… 2001-09-07 12:00:00 27 2 1 57 1.9 insi… ## 3 1bf0fe50cb bkt west… 2001-09-07 12:00:00 27 1 1 59 2.1 insi… ## 4 1bf0fe76f1 bkt west… 2001-09-07 12:00:00 27 6 1 59 2.1 insi… ## 5 1bf0fe845b bkt west… 2001-09-06 12:00:00 27 1 1 59 2.2 insi… ## 6 1bf0fe84ed bkt west… 2001-09-10 12:00:00 27 1 1 57 1.9 insi… ## 7 1bf0fe8846 bkt west… 2001-09-07 12:00:00 27 3 1 58 2 insi… ## 8 1bf0fe88d8 bkt west… 2001-09-10 12:00:00 27 2 1 58 2.1 insi… ## 9 1bf0fe8b79 bkt west… 2001-09-06 12:00:00 27 4 1 58 2 insi… ## 10 1bf0fe9504 bkt west… 2001-09-07 12:00:00 27 3 1 58 1.8 insi… ## # … with 54 more rows, and 17 more variables: section &lt;dbl&gt;, season &lt;dbl&gt;, isYOY &lt;lgl&gt;, date &lt;date&gt;, yday &lt;int&gt;, ## # year &lt;int&gt;, spawnDate &lt;date&gt;, emergeDate &lt;date&gt;, oneMonthDate &lt;date&gt;, threeMonthDate &lt;date&gt;, fiveMonthDate &lt;date&gt;, ## # spawn_emerge &lt;list&gt;, emerge_detect &lt;list&gt;, spawn_detect &lt;list&gt;, oneMonth &lt;list&gt;, threeMonth &lt;list&gt;, ## # fiveMonth &lt;list&gt; ggplot(cfirstObs2000_2001BKT, aes(observedLength, color = is.na(tag))) + geom_freqpoly() + geom_vline(xintercept = 60) 3.1.6 Models based on yearly means Filter firstObsUnnestedWB for bkt, bnt and min/maxYear d_WB_BKT_BNT &lt;- firstObsUnnestedWB %&gt;% filter(species != &quot;ats&quot;, year %in% minYear:maxYear) %&gt;% mutate(species01 = ifelse(species == &quot;bkt&quot;, 1, 0)) hist(d_WB_BKT_BNT$detectionDate, breaks = 250) d_BKT_BNT &lt;- firstObsUnnested %&gt;% filter(species != &quot;ats&quot;, year %in% minYear:maxYear) %&gt;% mutate(species01 = ifelse(species == &quot;bkt&quot;, 1, 0)) Mean model functions getMeansData &lt;- function(d, t, f) { means &lt;- d %&gt;% group_by(species, year) %&gt;% summarize(meanLength = mean(observedLength, na.rm = TRUE), meanEmerge_detect_sumTScaled = mean(emerge_detect_sumTScaled, na.rm = TRUE), meanEmerge_detect_sumFScaled = mean(emerge_detect_sumTScaled, na.rm = TRUE), meanTTime_sumTScaled = mean(get(t), na.rm = TRUE), meanFTime_sumFScaled = mean(get(f), na.rm = TRUE), meanYdayScaled = mean(ydayScaled, na.rm = TRUE), meanCount_Scaled = mean(count_Scaled, na.rm = TRUE) ) return(means) } getMeansDataByRiver &lt;- function(d, t, f) { means &lt;- d %&gt;% group_by(species, year, river) %&gt;% summarize(meanLength = mean(observedLength, na.rm = TRUE), meanEmerge_detect_sumTScaled = mean(emerge_detect_sumTScaled, na.rm = TRUE), meanEmerge_detect_sumFScaled = mean(emerge_detect_sumTScaled, na.rm = TRUE), meanTTime_sumTScaled = mean(get(t), na.rm = TRUE), meanFTime_sumFScaled = mean(get(f), na.rm = TRUE), meanYdayScaled = mean(ydayScaled, na.rm = TRUE), meanCount_Scaled = mean(count_Scaled, na.rm = TRUE) ) return(means) } plotMeans &lt;- function(means){ out &lt;- list() out[[1]] &lt;- ggplot(means, aes(meanTTime_sumTScaled, meanLength, color = species)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) out[[2]] &lt;- ggplot(means, aes(meanFTime_sumFScaled, meanLength, color = species)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) out[[3]] &lt;- ggplot(means, aes(meanTTime_sumTScaled, meanFTime_sumFScaled, color = species)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) return(out) } runMeanModels &lt;- function(means) { modLMMeans1 &lt;- lm(meanLength ~ (factor(species) + meanFTime_sumFScaled + meanTTime_sumTScaled + meanYdayScaled + meanCount_Scaled), data = means) modLMMeans2 &lt;- lm(meanLength ~ (factor(species) + meanFTime_sumFScaled + meanTTime_sumTScaled + meanYdayScaled + meanCount_Scaled)^2, data = means) modLMMeans3 &lt;- lm(meanLength ~ (factor(species) + meanFTime_sumFScaled + meanTTime_sumTScaled + meanYdayScaled + meanCount_Scaled)^3, data = means) return(list(modLMMeans1, modLMMeans2, modLMMeans3)) } Mean lengths by river. This is information only. Using the WB data only shown here and in the next graph for the models. Mean lengths for the mean length model. Graphs for variables that do not depend on number of months 3.1.6.1 Models with flow and temperature from previous one month ## [[1]] ## ## [[2]] ## ## [[3]] ## df AIC ## mod1[[2]] 17 176.2075 ## mod1[[3]] 27 181.7035 ## mod1[[1]] 7 181.8187 ## ## Call: ## lm(formula = meanLength ~ (factor(species) + meanFTime_sumFScaled + ## meanTTime_sumTScaled + meanYdayScaled + meanCount_Scaled), ## data = means) ## ## Residuals: ## Min 1Q Median 3Q Max ## -6.2779 -1.9839 -0.8754 1.0981 10.5908 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 72.4359 1.0722 67.558 &lt; 2e-16 *** ## factor(species)bnt 0.6550 1.3128 0.499 0.622039 ## meanFTime_sumFScaled 1.6769 0.3849 4.356 0.000184 *** ## meanTTime_sumTScaled -10.3842 2.3734 -4.375 0.000175 *** ## meanYdayScaled -3.4856 1.7314 -2.013 0.054554 . ## meanCount_Scaled -2.5187 0.7068 -3.564 0.001443 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.695 on 26 degrees of freedom ## Multiple R-squared: 0.6966, Adjusted R-squared: 0.6383 ## F-statistic: 11.94 on 5 and 26 DF, p-value: 4.544e-06 Relative importance for main effects model ## factor(species) meanFTime_sumFScaled meanTTime_sumTScaled meanYdayScaled meanCount_Scaled ## 0.00395522 0.24940595 0.19990058 0.06280977 0.18053989 3.1.6.2 Models with flow and temperature from previous three months ## [[1]] ## ## [[2]] ## ## [[3]] ## df AIC ## mod3[[3]] 27 177.0683 ## mod3[[2]] 17 181.7547 ## mod3[[1]] 7 187.3979 ## ## Call: ## lm(formula = meanLength ~ (factor(species) + meanFTime_sumFScaled + ## meanTTime_sumTScaled + meanYdayScaled + meanCount_Scaled), ## data = means) ## ## Residuals: ## Min 1Q Median 3Q Max ## -6.3569 -2.8523 0.3445 1.8018 9.2951 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 73.4882 1.8809 39.070 &lt; 2e-16 *** ## factor(species)bnt 0.8334 1.4312 0.582 0.565351 ## meanFTime_sumFScaled 2.2450 0.5866 3.827 0.000732 *** ## meanTTime_sumTScaled -8.8499 3.6769 -2.407 0.023489 * ## meanYdayScaled 0.7120 1.4287 0.498 0.622411 ## meanCount_Scaled -3.1604 0.7937 -3.982 0.000490 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.032 on 26 degrees of freedom ## Multiple R-squared: 0.6388, Adjusted R-squared: 0.5694 ## F-statistic: 9.197 on 5 and 26 DF, p-value: 3.902e-05 Relative importance for main effects model ## factor(species) meanFTime_sumFScaled meanTTime_sumTScaled meanYdayScaled meanCount_Scaled ## 0.004325792 0.281631981 0.060776249 0.066333713 0.225756051 3.1.6.3 Models with flow and temperature from previous five months ## [[1]] ## ## [[2]] ## ## [[3]] ## df AIC ## mod5[[3]] 27 167.4034 ## mod5[[1]] 7 193.2144 ## mod5[[2]] 17 208.3847 ## ## Call: ## lm(formula = meanLength ~ (factor(species) + meanFTime_sumFScaled + ## meanTTime_sumTScaled + meanYdayScaled + meanCount_Scaled), ## data = means) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.9186 -3.3732 0.3856 2.4470 11.8564 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 71.1144 1.9342 36.767 &lt; 2e-16 *** ## factor(species)bnt 0.8911 1.5671 0.569 0.57450 ## meanFTime_sumFScaled 2.6934 0.8705 3.094 0.00468 ** ## meanTTime_sumTScaled -3.5748 2.9746 -1.202 0.24029 ## meanYdayScaled 3.2403 1.5506 2.090 0.04657 * ## meanCount_Scaled -2.8957 0.8613 -3.362 0.00240 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.415 on 26 degrees of freedom ## Multiple R-squared: 0.5668, Adjusted R-squared: 0.4835 ## F-statistic: 6.805 on 5 and 26 DF, p-value: 0.0003537 Relative importance for main effects model ## factor(species) meanFTime_sumFScaled meanTTime_sumTScaled meanYdayScaled meanCount_Scaled ## 0.004330339 0.226812955 0.017322018 0.107186866 0.211177826 r-squared values and AICs for 1st, 2nd (2-way interactions) and 3rd (3-way interactions) order models Order r2 numMonths 1 0.697 1 2 0.864 1 3 0.913 1 Order r2 numMonths 1 0.639 3 2 0.838 3 3 0.925 3 Order r2 numMonths 1 0.567 5 2 0.628 5 3 0.945 5 df AIC numMonths mod1[[2]] 17 176.207 1 mod1[[3]] 27 181.703 1 mod1[[1]] 7 181.819 1 df AIC numMonths mod3[[3]] 27 177.068 3 mod3[[2]] 17 181.755 3 mod3[[1]] 7 187.398 3 df AIC numMonths mod5[[3]] 27 167.403 5 mod5[[1]] 7 193.214 5 mod5[[2]] 17 208.385 5 Relative importance of main effects models (repeat of above, but all in one place here) var relImp numMonths factor(species) 0.004 1 meanFTime_sumFScaled 0.249 1 meanTTime_sumTScaled 0.200 1 meanYdayScaled 0.063 1 meanCount_Scaled 0.181 1 var relImp numMonths factor(species) 0.004 3 meanFTime_sumFScaled 0.282 3 meanTTime_sumTScaled 0.061 3 meanYdayScaled 0.066 3 meanCount_Scaled 0.226 3 var relImp numMonths factor(species) 0.004 5 meanFTime_sumFScaled 0.227 5 meanTTime_sumTScaled 0.017 5 meanYdayScaled 0.107 5 meanCount_Scaled 0.211 5 3.1.7 Models with extreme flow events (droughts) We get negative cumulFlows because we have some negative flows from the flow extension model # put some of these calculations into envDataWB envDataWBFlow = envDataWB %&gt;% mutate(year = year(dateDate), yday = yday(dateDate), flowNoNAs = ifelse(is.na(flow), 0, flow), tempNoNAs = ifelse(is.na(temperature), 0, temperature)) %&gt;% filter(year %in% minYear:maxYear, yday &gt; 100, yday &lt; 300, river == &quot;west brook&quot;) %&gt;% group_by(year) %&gt;% mutate(cumulFlow = cumsum(flowNoNAs), cumulFlow01 = cumulFlow / max(cumulFlow), cumulTemp = cumsum(tempNoNAs)) %&gt;% ungroup() firstObsYears &lt;- firstObs %&gt;% filter(year %in% minYear:maxYear, yday &gt; 100, yday &lt; 300) ggplot(envDataWBFlow, aes(yday, flow)) + geom_point(aes(yday, observedLength/20), size = 0.75, alpha = 0.2, color = &#39;lightblue&#39;, data = firstObsYears) + geom_point(size = 0.5) + scale_x_continuous(breaks = seq(0,300, 30)) + facet_wrap(~year) ggplot(envDataWBFlow, aes(yday, cumulFlow / 10)) + geom_point(aes(yday, observedLength / 20), size = 0.75, alpha = 0.2, color = &#39;lightblue&#39;, data = firstObsYears) + geom_point(size = 0.5, color = &#39;darkgrey&#39;) + geom_point(aes(yday, cumulTemp / 800), size = 0.5, color = &quot;orange&quot;, data = envDataWBFlow) + geom_point(aes(yday, flow), size = 0.5, data = envDataWBFlow) + scale_x_continuous(breaks = seq(0, 300, 30)) + #theme_publication() + facet_wrap(~year) ggplot(envDataWBFlow, aes(yday, cumulFlow, color = (year))) + geom_point() + scale_x_continuous(breaks = seq(0, 300, 30)) ggplot(envDataWBFlow, aes(yday, cumulTemp, color = (year))) + geom_point() + #geom_point(aes(yday, cumulTemp / 800, color = factor(year)), data = tmp) + scale_x_continuous(breaks = seq(0, 300, 30)) Is there a sampling section effect? Note: there are fish in sections &gt; 50 for years 2002 and 2003, need to filter out early ggplot(d_WB_BKT_BNT %&gt;% filter( section &lt;= 47), aes(factor(section), observedLength)) + geom_boxplot() + geom_smooth() + facet_wrap(~year) ggplot(d_WB_BKT_BNT %&gt;% filter( section &lt;= 47), aes(factor(year), observedLength)) + geom_boxplot() + geom_smooth() + facet_wrap(~section) 3.1.8 Models based on individual observations Probably not use these, too much individual variation 3.1.8.1 Are flow and temperature correlated for individual observations? ggplot(firstObsUnnestedWB, aes(oneMonth_sumTScaled, oneMonth_sumFScaled)) + geom_point(aes(color = (year))) + geom_smooth(method = &quot;lm&quot;) + facet_wrap(~ species) ggplot(firstObsUnnestedWB, aes(threeMonth_sumTScaled, threeMonth_sumFScaled)) + geom_point(aes(color = (year))) + geom_smooth(method = &quot;lm&quot;) + facet_wrap(~ species) ggplot(firstObsUnnestedWB, aes(fiveMonth_sumTScaled, fiveMonth_sumFScaled)) + geom_point(aes(color = (year))) + geom_smooth(method = &quot;lm&quot;) + facet_wrap(~ species) # water getting warmer during a sample ggplot(firstObsUnnestedWB, aes(fiveMonth_sumTScaled, fiveMonth_sumFScaled)) + geom_point(aes(color = (yday))) + geom_smooth(method = &quot;lm&quot;) + facet_wrap(~ species) cor(firstObsUnnestedWB$oneMonth_sumTScaled, firstObsUnnestedWB$oneMonth_sumFScaled) ## [1] -0.1778785 cor(firstObsUnnestedWB$threeMonth_sumTScaled, firstObsUnnestedWB$threeMonth_sumFScaled) ## [1] -0.01625096 cor(firstObsUnnestedWB$fiveMonth_sumTScaled, firstObsUnnestedWB$fiveMonth_sumFScaled) ## [1] -0.09445786 # brook trout firstObsUnnestedWB_BKT &lt;- firstObsUnnestedWB %&gt;% filter(species == &quot;bkt&quot;) cor(firstObsUnnestedWB_BKT$oneMonth_sumTScaled, firstObsUnnestedWB_BKT$oneMonth_sumFScaled) ## [1] 0.05756251 cor(firstObsUnnestedWB_BKT$threeMonth_sumTScaled, firstObsUnnestedWB_BKT$threeMonth_sumFScaled) ## [1] -0.008944376 cor(firstObsUnnestedWB_BKT$fiveMonth_sumTScaled, firstObsUnnestedWB_BKT$fiveMonth_sumFScaled) ## [1] -0.1172725 # brown trout firstObsUnnestedWB_BNT &lt;- firstObsUnnestedWB %&gt;% filter(species == &quot;bnt&quot;) cor(firstObsUnnestedWB_BNT$oneMonth_sumTScaled, firstObsUnnestedWB_BNT$oneMonth_sumFScaled) ## [1] 0.1403489 cor(firstObsUnnestedWB_BNT$threeMonth_sumTScaled, firstObsUnnestedWB_BNT$threeMonth_sumFScaled) ## [1] -0.103418 cor(firstObsUnnestedWB_BNT$fiveMonth_sumTScaled, firstObsUnnestedWB_BNT$fiveMonth_sumFScaled) ## [1] -0.009179518 Do fish from long samples get bigger over time? No clear evidence. ggplot(firstObsUnnestedWB, aes(yday, observedLength)) + geom_point(alpha = 0.05) + geom_smooth(method = &quot;lm&quot;) + facet_wrap(~year) Assign the month interval (one, three, five) for flow and temperature variables. The variable will be accessed using e.g. get(tTime) in formulas and filters tTime &lt;- &quot;threeMonth_sumTScaled&quot; fTime &lt;- &quot;threeMonth_sumFScaled&quot; #&quot;fiveMonth_sumFScaled&quot; library(lme4) library(relaimpo) modLM1 &lt;- lm(observedLength ~ (factor(species) * get(tTime) * get(fTime) * ydayScaled * count_Scaled), data = d_WB_BKT_BNT) modLM2 &lt;- lm(observedLength ~ (factor(species) + get(tTime) + get(fTime) + ydayScaled + count_Scaled), data = d_WB_BKT_BNT) modLM3 &lt;- lm(observedLength ~ (factor(species) + get(tTime) + get(fTime) + ydayScaled + count_Scaled)^2, data = d_WB_BKT_BNT) modLM1a &lt;- lm(observedLength ~ (factor(species)), data = d_WB_BKT_BNT) modLM1b &lt;- lm(observedLength ~ (factor(species) * get(tTime)), data = d_WB_BKT_BNT) modLM1c &lt;- lm(observedLength ~ (factor(species) * get(fTime)), data = d_WB_BKT_BNT) modLM1d &lt;- lm(observedLength ~ (factor(species) * ydayScaled), data = d_WB_BKT_BNT) modLM1e &lt;- lm(observedLength ~ (factor(species) * count_Scaled), data = d_WB_BKT_BNT) AIC(modLM1, modLM2, modLM3, modLM1a, modLM1b, modLM1c, modLM1d, modLM1e) %&gt;% arrange(AIC) ## df AIC ## modLM1 33 61643.33 ## modLM3 17 61807.67 ## modLM2 7 62669.02 ## modLM1c 5 63224.10 ## modLM1e 5 63624.09 ## modLM1d 5 63755.95 ## modLM1b 5 63777.11 ## modLM1a 3 63918.49 #relaimpo::calc.relimp(modLM2) # slow for bigger models # get &#39;boundary (singular)&#39; error with model without 2-way interaction #modLMER2 &lt;- lmer(observedLength ~ (factor(species) + emerge_detect_sumTScaled + emerge_detect_sumFScaled + ydayScaled +count_Scaled)^2 + 1|year, data = d_WB_BKT_BNT) #https://gist.github.com/BERENZ/e9b581a4b7160357934e calc.relip.mm &lt;- function(model,type=&#39;lmg&#39;) { if (!isLMM(model) &amp; !isGLMM(model)) { stop(&#39;Currently supports only lmer/glmer objects&#39;, call. = FALSE) } require(lme4) X &lt;- getME(model,&#39;X&#39;) X &lt;- X[,-1] Y &lt;- getME(model,&#39;y&#39;) s_resid &lt;- sigma(model) s_effect &lt;- getME(model,&#39;theta&#39;)*s_resid s2 &lt;- sum(s_resid^2,s_effect^2) V &lt;- Diagonal(x = s2,n=nrow(X)) YX &lt;- cbind(Y,X) cov_XY &lt;- solve( t(YX) %*% solve(V) %*% as.matrix(YX)) colnames(cov_XY) &lt;- rownames(cov_XY) &lt;- colnames(YX) importances &lt;- calc.relimp(as.matrix(cov_XY),rela=T,type=type) return(importances) } #modLMER1 &lt;- lmer(observedLength ~ (factor(species) + get(tTime)|year + get(fTime)|year + ydayScaled|year + count_Scaled|year), data = d_WB_BKT_BNT) modLMER1 &lt;- lmer(observedLength ~ (factor(species) * get(tTime) * get(fTime) * ydayScaled * count_Scaled) + (1|year), data = d_WB_BKT_BNT) modLMER2 &lt;- lmer(observedLength ~ (factor(species) + get(tTime) + get(fTime) + ydayScaled + count_Scaled) + (1|year), data = d_WB_BKT_BNT) modLMER3 &lt;- lmer(observedLength ~ (factor(species) + get(tTime) + get(fTime) + ydayScaled + count_Scaled)^2 + (1|year), data = d_WB_BKT_BNT) # one-by-one modLMER1a &lt;- lmer(observedLength ~ (factor(species)) + (1|year), data = d_WB_BKT_BNT) modLMER1b &lt;- lmer(observedLength ~ (factor(species) * get(tTime)) + (1|year), data = d_WB_BKT_BNT) modLMER1c &lt;- lmer(observedLength ~ (factor(species) * get(fTime)) + (1|year), data = d_WB_BKT_BNT) modLMER1d &lt;- lmer(observedLength ~ (factor(species) * ydayScaled) + (1|year), data = d_WB_BKT_BNT) modLMER1e &lt;- lmer(observedLength ~ (factor(species) * count_Scaled) + (1|year), data = d_WB_BKT_BNT) AIC(modLMER1, modLMER2, modLMER3, modLMER1a, modLMER1b, modLMER1c, modLMER1d, modLMER1e) %&gt;% arrange(AIC) ## df AIC ## modLMER1 34 61236.76 ## modLMER3 18 61411.21 ## modLMER1d 6 61466.63 ## modLMER2 8 61470.46 ## modLMER1e 6 61471.21 ## modLMER1c 6 61472.64 ## modLMER1b 6 61473.34 ## modLMER1a 4 61475.77 calc.relip.mm(modLMER3) ## Response variable: Y ## Total response variance: 3.893283e-05 ## ## 15 Regressors: ## factor(species)bnt get(tTime) get(fTime) ydayScaled count_Scaled factor(species)bnt:get(tTime) factor(species)bnt:get(fTime) factor(species)bnt:ydayScaled factor(species)bnt:count_Scaled get(tTime):get(fTime) get(tTime):ydayScaled get(tTime):count_Scaled get(fTime):ydayScaled get(fTime):count_Scaled ydayScaled:count_Scaled ## Proportion of variance explained by model: 94.15% ## Metrics are normalized to sum to 100% (rela=TRUE). ## ## Relative importance metrics: ## ## lmg ## factor(species)bnt 0.097760307 ## get(tTime) 0.419878608 ## get(fTime) 0.092676088 ## ydayScaled 0.033569860 ## count_Scaled 0.078624107 ## factor(species)bnt:get(tTime) 0.065441939 ## factor(species)bnt:get(fTime) 0.012771321 ## factor(species)bnt:ydayScaled 0.001781329 ## factor(species)bnt:count_Scaled 0.019728183 ## get(tTime):get(fTime) 0.071941193 ## get(tTime):ydayScaled 0.029205652 ## get(tTime):count_Scaled 0.041529196 ## get(fTime):ydayScaled 0.011797805 ## get(fTime):count_Scaled 0.012243731 ## ydayScaled:count_Scaled 0.011050681 ## ## Average coefficients for different model sizes: ## ## 1X 2Xs 3Xs 4Xs 5Xs 6Xs ## factor(species)bnt -0.0054984017 -0.0050704814 -0.0047545824 -0.0045389793 -0.0044124337 -4.364877e-03 ## get(tTime) -0.0065705658 -0.0064807310 -0.0063924113 -0.0063084199 -0.0062305836 -6.159911e-03 ## get(fTime) -0.0086478481 -0.0078930543 -0.0071804983 -0.0065359969 -0.0059811793 -5.531536e-03 ## ydayScaled 0.0031793857 0.0027052187 0.0022831959 0.0019197886 0.0016131058 1.358765e-03 ## count_Scaled -0.0083583700 -0.0078052106 -0.0072775852 -0.0068141491 -0.0064372666 -6.153114e-03 ## factor(species)bnt:get(tTime) 0.0025119506 0.0020567879 0.0016471742 0.0012672530 0.0009056673 5.550952e-04 ## factor(species)bnt:get(fTime) 0.0060183654 0.0047218822 0.0036288022 0.0027025061 0.0019065191 1.208199e-03 ## factor(species)bnt:ydayScaled -0.0002196817 -0.0002660699 -0.0003114297 -0.0003574487 -0.0004026767 -4.443192e-04 ## factor(species)bnt:count_Scaled 0.0067855005 0.0051864389 0.0038694571 0.0027807734 0.0018716941 1.101015e-03 ## get(tTime):get(fTime) 0.0032931088 0.0027736154 0.0023758016 0.0020597885 0.0017908497 1.540839e-03 ## get(tTime):ydayScaled -0.0013525912 -0.0010122936 -0.0007224178 -0.0004705386 -0.0002496660 -5.582531e-05 ## get(tTime):count_Scaled 0.0023356306 0.0018431949 0.0014769807 0.0011882760 0.0009424538 7.171659e-04 ## get(fTime):ydayScaled -0.0024680341 -0.0027398874 -0.0028756456 -0.0029246083 -0.0029130457 -2.855016e-03 ## get(fTime):count_Scaled 0.0011703243 -0.0002162869 -0.0012391144 -0.0020246858 -0.0026437455 -3.130556e-03 ## ydayScaled:count_Scaled -0.0060601403 -0.0042294345 -0.0028505144 -0.0018549978 -0.0011694592 -7.240908e-04 ## 7Xs 8Xs 9Xs 10Xs 11Xs 12Xs ## factor(species)bnt -0.0043881071 -4.475745e-03 -0.0046223344 -0.0048218598 -5.066310e-03 -5.345099e-03 ## get(tTime) -0.0060966732 -6.040385e-03 -0.0059898316 -0.0059432666 -5.898799e-03 -5.854907e-03 ## get(fTime) -0.0051950013 -4.970278e-03 -0.0048458768 -0.0048005235 -4.804691e-03 -4.822743e-03 ## ydayScaled 0.0011534566 9.968974e-04 0.0008927463 0.0008487173 8.757443e-04 9.858444e-04 ## count_Scaled -0.0059544293 -5.824393e-03 -0.0057402718 -0.0056771394 -5.612643e-03 -5.533014e-03 ## factor(species)bnt:get(tTime) 0.0002111539 -1.287035e-04 -0.0004659555 -0.0008012831 -1.134412e-03 -1.463815e-03 ## factor(species)bnt:get(fTime) 0.0005806889 3.882144e-06 -0.0005343247 -0.0010365233 -1.495172e-03 -1.894321e-03 ## factor(species)bnt:ydayScaled -0.0004787153 -5.010271e-04 -0.0005046357 -0.0004807007 -4.185323e-04 -3.073680e-04 ## factor(species)bnt:count_Scaled 0.0004359225 -1.482176e-04 -0.0006682334 -0.0011336990 -1.548402e-03 -1.913621e-03 ## get(tTime):get(fTime) 0.0012890129 1.022548e-03 0.0007363939 0.0004323806 1.179063e-04 -1.953488e-04 ## get(tTime):ydayScaled 0.0001139192 2.627106e-04 0.0003945425 0.0005145068 6.287198e-04 7.438227e-04 ## get(tTime):count_Scaled 0.0005002465 2.873275e-04 0.0000795192 -0.0001188814 -3.028894e-04 -4.695265e-04 ## get(fTime):ydayScaled -0.0027585842 -2.629436e-03 -0.0024725885 -0.0022926181 -2.093092e-03 -1.875890e-03 ## get(fTime):count_Scaled -0.0034980296 -3.748389e-03 -0.0038800558 -0.0038917388 -3.784748e-03 -3.564784e-03 ## ydayScaled:count_Scaled -0.0004553432 -3.058715e-04 -0.0002237541 -0.0001619201 -7.825575e-05 6.336058e-05 ## 13Xs 14Xs 15Xs ## factor(species)bnt -0.0056461457 -5.959040e-03 -0.0062796744 ## get(tTime) -0.0058109959 -5.767910e-03 -0.0057282815 ## get(fTime) -0.0048158521 -4.746171e-03 -0.0045799533 ## ydayScaled 0.0011888137 1.489186e-03 0.0018864288 ## count_Scaled -0.0054389891 -5.349606e-03 -0.0053039170 ## factor(species)bnt:get(tTime) -0.0017867916 -2.100436e-03 -0.0024036120 ## factor(species)bnt:get(fTime) -0.0022142922 -2.438114e-03 -0.0025565105 ## factor(species)bnt:ydayScaled -0.0001392003 8.910015e-05 0.0003764257 ## factor(species)bnt:count_Scaled -0.0022331996 -2.519186e-03 -0.0027966124 ## get(tTime):get(fTime) -0.0004927221 -7.584234e-04 -0.0009773304 ## get(tTime):ydayScaled 0.0008660298 1.000118e-03 0.0011493099 ## get(tTime):count_Scaled -0.0006202278 -7.623248e-04 -0.0009098491 ## get(fTime):ydayScaled -0.0016406077 -1.384448e-03 -0.0011021992 ## get(fTime):count_Scaled -0.0032439647 -2.841580e-03 -0.0023829029 ## ydayScaled:count_Scaled 0.0002913468 6.252846e-04 0.0010782461 library(MuMIn) r.squaredGLMM(modLMER1) ## R2m R2c ## [1,] 0.2001733 0.6185189 summary(modLMER1) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: observedLength ~ (factor(species) * get(tTime) * get(fTime) * ydayScaled * count_Scaled) + (1 | year) ## Data: d_WB_BKT_BNT ## ## REML criterion at convergence: 61168.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.4018 -0.6876 -0.0288 0.6436 6.6810 ## ## Random effects: ## Groups Name Variance Std.Dev. ## year (Intercept) 85.83 9.264 ## Residual 78.27 8.847 ## Number of obs: 8499, groups: year, 16 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 80.8481 4.1701 19.388 ## factor(species)bnt -4.9284 1.4042 -3.510 ## get(tTime) -21.6554 7.2622 -2.982 ## get(fTime) 9.4220 4.0516 2.325 ## ydayScaled -4.0731 2.7473 -1.483 ## count_Scaled -6.0394 4.2307 -1.427 ## factor(species)bnt:get(tTime) 12.0455 2.5799 4.669 ## factor(species)bnt:get(fTime) 0.3451 1.5233 0.227 ## get(tTime):get(fTime) -16.8596 7.6738 -2.197 ## factor(species)bnt:ydayScaled 0.6682 3.0523 0.219 ## get(tTime):ydayScaled 1.0575 5.4994 0.192 ## get(fTime):ydayScaled -9.3848 2.6598 -3.528 ## factor(species)bnt:count_Scaled 0.8883 1.0017 0.887 ## get(tTime):count_Scaled 13.6476 9.5497 1.429 ## get(fTime):count_Scaled -15.7569 3.8771 -4.064 ## ydayScaled:count_Scaled 9.2820 2.0254 4.583 ## factor(species)bnt:get(tTime):get(fTime) -7.3923 3.1937 -2.315 ## factor(species)bnt:get(tTime):ydayScaled 2.1106 6.5449 0.322 ## factor(species)bnt:get(fTime):ydayScaled -0.9930 2.7942 -0.355 ## get(tTime):get(fTime):ydayScaled 10.3113 5.9959 1.720 ## factor(species)bnt:get(tTime):count_Scaled -2.1328 2.5544 -0.835 ## factor(species)bnt:get(fTime):count_Scaled 6.4230 1.8794 3.418 ## get(tTime):get(fTime):count_Scaled 18.3310 9.7834 1.874 ## factor(species)bnt:ydayScaled:count_Scaled -5.4154 2.0331 -2.664 ## get(tTime):ydayScaled:count_Scaled -18.1465 5.1346 -3.534 ## get(fTime):ydayScaled:count_Scaled 5.0809 2.7461 1.850 ## factor(species)bnt:get(tTime):get(fTime):ydayScaled 6.9942 7.1420 0.979 ## factor(species)bnt:get(tTime):get(fTime):count_Scaled -16.6416 4.1143 -4.045 ## factor(species)bnt:get(tTime):ydayScaled:count_Scaled 12.3811 5.7403 2.157 ## factor(species)bnt:get(fTime):ydayScaled:count_Scaled 0.8281 3.2880 0.252 ## get(tTime):get(fTime):ydayScaled:count_Scaled -15.0936 7.8332 -1.927 ## factor(species)bnt:get(tTime):get(fTime):ydayScaled:count_Scaled 0.3270 9.4661 0.035 ranef(modLMER1) ## $year ## (Intercept) ## 2000 8.8500565 ## 2001 -8.4985347 ## 2002 -7.3323965 ## 2003 -1.5660312 ## 2004 -5.1466870 ## 2005 -1.0172900 ## 2006 3.5989690 ## 2007 10.3090430 ## 2008 -0.7230606 ## 2009 6.7853759 ## 2010 5.6472890 ## 2011 -21.6975629 ## 2012 -3.4055069 ## 2013 9.6487802 ## 2014 4.0152310 ## 2015 0.5323252 ## ## with conditional variances for &quot;year&quot; Raw data exploration following the models relaimpo::calc.relimp(modLM2) - other models are too big lmg factor(species) 0.005339423 emerge_detect_sumTScaled 0.006883496 emerge_detect_sumFScaled 0.063450197 ydayScaled 0.012116064 count_Scaled 0.028031531 ggplot(d_WB_BKT_BNT, aes(get(fTime), observedLength)) + geom_point(alpha = 0.2) + geom_smooth(method = &quot;lm&quot;) + facet_wrap(~species) ggplot(d_WB_BKT_BNT, aes(count_Scaled, observedLength)) + geom_point(alpha = 0.2) + geom_smooth(method = &quot;lm&quot;) + facet_wrap(~species) ggplot(d_WB_BKT_BNT, aes(ydayScaled, observedLength)) + geom_point(alpha = 0.2) + geom_smooth(method = &quot;lm&quot;) + facet_wrap(~species) ggplot(d_WB_BKT_BNT, aes(get(tTime), observedLength)) + geom_point(alpha = 0.2) + geom_smooth(method = &quot;lm&quot;) + facet_wrap(~species) 3.2 Flow model dataFlow &lt;- read.csv(&quot;./dataIn/wbFlow/EcoDrought_Continuous_MA.csv&quot;) tibble(dataFlow) ## # A tibble: 582,388 × 9 ## Station_No Site_Name DateTime_EST GageHeight_Hobo_ft Discharge_Hobo_cfs WaterTemperature_HOBO_D… AirPressure_PSI ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1171000 Avery Brook 2/20/2020 0:00 4.17 5.37 32.0 NA ## 2 1171000 Avery Brook 2/20/2020 0:15 4.17 5.3 32.0 NA ## 3 1171000 Avery Brook 2/20/2020 0:30 4.16 5.17 32.0 NA ## 4 1171000 Avery Brook 2/20/2020 0:45 4.17 5.27 32.0 NA ## 5 1171000 Avery Brook 2/20/2020 1:00 4.17 5.3 32.0 NA ## 6 1171000 Avery Brook 2/20/2020 1:15 4.15 4.94 31.9 NA ## 7 1171000 Avery Brook 2/20/2020 1:30 4.13 4.56 31.9 NA ## 8 1171000 Avery Brook 2/20/2020 1:45 4.1 4.14 31.9 NA ## 9 1171000 Avery Brook 2/20/2020 2:00 4.08 3.84 31.9 NA ## 10 1171000 Avery Brook 2/20/2020 2:15 4.09 4.02 31.9 NA ## # … with 582,378 more rows, and 2 more variables: AirTemperature_HOBO_degF &lt;dbl&gt;, X &lt;lgl&gt; table(dataFlow$Site_Name) ## ## Avery Brook Jimmy Brook Mitchell Brook Obear Brook Lower Sanderson Brook ## 56536 57849 56978 60392 55336 ## West Brook 0 West Brook Lower West Brook Reservoir West Brook Upper West Whately Brook ## 58548 61279 61059 57301 57110 d &lt;- dataFlow %&gt;% filter(Site_Name %in% c(&quot;Jimmy Brook&quot;, &quot;Mitchell Brook&quot;, &quot;Obear Brook Lower&quot;, &quot;West Brook 0&quot;)) %&gt;% mutate(date = mdy_hm(DateTime_EST), site = recode(Site_Name, &quot;Jimmy Brook&quot; = &quot;OL&quot;, &quot;Mitchell Brook&quot; = &quot;OS&quot;, &quot;Obear Brook Lower&quot; = &quot;IS&quot;, &quot;West Brook 0&quot; = &quot;WB&quot;), dischargeLog = log(Discharge_Hobo_cfs + 0.01)) d %&gt;% filter(is.infinite(dischargeLog)) ## [1] Station_No Site_Name DateTime_EST GageHeight_Hobo_ft ## [5] Discharge_Hobo_cfs WaterTemperature_HOBO_DegF AirPressure_PSI AirTemperature_HOBO_degF ## [9] X date site dischargeLog ## &lt;0 rows&gt; (or 0-length row.names) scaleCol &lt;- function(d){ return (d - mean(d, na.rm = TRUE)) / sd(d, na.rm = TRUE) } # hard-coded for now dWide &lt;- d %&gt;% pivot_wider(id_cols = date, values_from = dischargeLog, names_from = site ) %&gt;% mutate( OLScaled = scaleCol(OL), ISScaled = scaleCol(IS), OSScaled = scaleCol(OS), WBScaled = scaleCol(WB), yday = yday(date), year = year(date) ) ggplot(d, aes(date, dischargeLog, color = Site_Name)) + geom_point(size = 0.02) + facet_wrap(~Site_Name) ggpairs(dWide, columns = 6:9, mapping = ggplot2::aes(color = as.factor(year), alpha = 0.7), #diag = list(continuous = myDens), lower = list(continuous = wrap(&quot;points&quot;, alpha = 0.3, size=0.1), combo = wrap(&quot;dot&quot;, alpha = 0.4, size=0.2)) ) ggpairs(dWide %&gt;% filter(yday &gt; 90, yday &lt; 300), columns = 6:9, mapping = ggplot2::aes(color = as.factor(year)), lower = list(continuous = wrap(&quot;points&quot;, alpha = 0.3, size=0.1), combo = wrap(&quot;dot&quot;, alpha = 0.4, size=0.2)) ) ggpairs(dWide %&gt;% filter(yday == 110), columns = 8:11, mapping = ggplot2::aes(color = as.factor(year)), lower = list(continuous = wrap(&quot;points&quot;, alpha = 0.3, size=0.2), combo = wrap(&quot;dot&quot;, alpha = 0.4, size=0.2)) ) #mod0 &lt;- lmer(OL ~ WB * yday + as.factor(year) + 1|yday, data = dWide) 3.3 Flow effects on survival (phi) models The goal of this modelling exercise is to evaluate the effect of new tributary-specific stream flow estimates on survival of brook trout and brown trout. We will compare survival across the WB and tributaries with flow input data as 1) single flow estimate for all locations (historical approach) and 2) hindcasted flows for each tributary based on new tributary-specific flows which are available since 2000. The goal is to find the best structure for the survival model, then compare survival estimates with tributary-specific flow to estimates with common flow across locations. Structure options include [species, cohort, season, isYOY, flow, flow^2] rerunSurivalModels &lt;- FALSE plotMCMCOutput &lt;- TRUE load(&#39;./models/cmrFlowWB/dataOut/eh_2002200320042005200620072008200920102011201220132014_wb obear.RData&#39;) 3.3.1 Model phi_p Single estimates of phi and p (across, time, cohorts, flow) #### Set up and run model # Following https://oliviergimenez.github.io/bayesian-cr-workshop/worksheets/4_demo.html if (rerunSurivalModels) { y &lt;- eh$eh nSeasons &lt;- nrow(unique(eh$seasons)) nCohorts &lt;- nrow(unique(eh$cohorts)) hmm.phi_p &lt;- nimbleCode({ phi ~ dunif(0, 1) # prior survival p ~ dunif(0, 1) # prior detection # likelihood gamma[1,1] &lt;- phi # Pr(alive t -&gt; alive t+1) gamma[1,2] &lt;- 1 - phi # Pr(alive t -&gt; dead t+1) gamma[2,1] &lt;- 0 # Pr(dead t -&gt; alive t+1) gamma[2,2] &lt;- 1 # Pr(dead t -&gt; dead t+1) delta[1] &lt;- 1 # Pr(alive t = 1) = 1 delta[2] &lt;- 0 # Pr(dead t = 1) = 0 omega[1,1] &lt;- 1 - p # Pr(alive t -&gt; non-detected t) omega[1,2] &lt;- p # Pr(alive t -&gt; detected t) omega[2,1] &lt;- 1 # Pr(dead t -&gt; non-detected t) omega[2,2] &lt;- 0 # Pr(dead t -&gt; detected t) for (i in 1:N){ z[i,first[i]] ~ dcat(delta[1:2]) for (j in (first[i]+1):last[i]){ z[i,j] ~ dcat(gamma[z[i,j-1], 1:2]) y[i,j] ~ dcat(omega[z[i,j], 1:2]) } } }) first &lt;- eh$first #apply(y, 1, function(x) min(which(x !=0))) last &lt;- eh$last myConstants &lt;- list(N = nrow(y), T = ncol(y), first = first, last = last) myData &lt;- list(y = y + 1) zinits &lt;- y + 1 # non-detection -&gt; alive zinits[zinits == 2] &lt;- 1 # dead -&gt; alive initialValues &lt;- function() list(phi = runif(1,0,1), p = runif(1,0,1), z = zinits ) parametersToSave &lt;- c(&quot;phi&quot;, &quot;p&quot;) nIter &lt;- 5000 nBurnin &lt;- 1000 nChains &lt;- 2 thinRate = 5 start &lt;- Sys.time() Rmodel &lt;- nimbleModel( code = hmm.phi_p, constants = myConstants, data = myData, inits = initialValues(), calculate = FALSE ) conf &lt;- configureMCMC( Rmodel, monitors = parametersToSave ) Rmcmc &lt;- buildMCMC(conf, useConjugacy = FALSE) Cmodel &lt;- compileNimble(Rmodel) Cmcmc &lt;- compileNimble(Rmcmc, project = Rmodel) mcmc.phi_p &lt;- runMCMC( Cmcmc, niter = nIter, nburnin = nBurnin, thin = thinRate, nchains = nChains ) end &lt;- Sys.time() elapsed_phi_p &lt;- end - start toSave &lt;- list( mcmc = mcmc.phi_p, elapsed = elapsed_phi_p, name = &quot;phi_p&quot;, myConstants = myConstants, nIter = nIter, nBurnin = nBurnin, thinRate = thinRate, nSeasons = nSeasons, nCohorts = nCohorts, nChains = nChains ) save(toSave, file = paste0(&#39;./models/cmrFlowWB/runsOut/mcmc_phi_p_&#39;, substr(end,1,13), &#39;.RData&#39;)) save(toSave, file = &#39;./models/cmrFlowWB/runsOut/mcmc_phi_p_mostRecent.RData&#39;) } else { load(&#39;./models/cmrFlowWB/runsOut/mcmc_phi_p_mostRecent.RData&#39;) } if(plotMCMCOutput) { #MCMCsummary(object = mcmc.phi_p, round = 2) MCMCplot(object = toSave$mcmc) priors &lt;- runif(toSave$nIter * toSave$nChains, 0, 1) MCMCtrace(object = toSave$mcmc, ISB = FALSE, exact = TRUE, params = c(&quot;phi&quot;, &quot;p&quot;), pdf = FALSE, priors = priors) } 3.3.2 Model phiT_pT Phi and p vary by sampling occasion (time) #### Set up and run model # Following https://oliviergimenez.github.io/bayesian-cr-workshop/worksheets/4_demo.html if (rerunSurivalModels) { y &lt;- eh$eh nSeasons &lt;- nrow(unique(eh$seasons)) nCohorts &lt;- nrow(unique(eh$cohorts)) hmm.phiT_pT &lt;- nimbleCode({ delta[1] &lt;- 1 # Pr(alive t = 1) = 1 delta[2] &lt;- 0 # Pr(dead t = 1) = 0 for (t in 1:(T-1)){ # loop over time phi[t] ~ dunif(0, 1) # prior survival gamma[1,1,t] &lt;- phi[t] # Pr(alive t -&gt; alive t+1) gamma[1,2,t] &lt;- 1 - phi[t] # Pr(alive t -&gt; dead t+1) gamma[2,1,t] &lt;- 0 # Pr(dead t -&gt; alive t+1) gamma[2,2,t] &lt;- 1 # Pr(dead t -&gt; dead t+1) p[t] ~ dunif(0, 1) # prior detection omega[1,1,t] &lt;- 1 - p[t] # Pr(alive t -&gt; non-detected t) omega[1,2,t] &lt;- p[t] # Pr(alive t -&gt; detected t) omega[2,1,t] &lt;- 1 # Pr(dead t -&gt; non-detected t) omega[2,2,t] &lt;- 0 # Pr(dead t -&gt; detected t) } # likelihood for (i in 1:N){ z[i,first[i]] ~ dcat(delta[1:2]) for (j in (first[i]+1):last[i]){ z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1]) y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1]) } } }) first &lt;- eh$first #apply(y, 1, function(x) min(which(x !=0))) last &lt;- eh$last myConstants &lt;- list(N = nrow(y), T = ncol(y), first = first, last = last) myData &lt;- list(y = y + 1) zinits &lt;- y + 1 # non-detection -&gt; alive zinits[zinits == 2] &lt;- 1 # dead -&gt; alive initialValues &lt;- function() list(phi = runif(myConstants$T - 1, 0, 1), p = runif(myConstants$T - 1, 0, 1), z = zinits) parametersToSave &lt;- c(&quot;phi&quot;, &quot;p&quot;) nIter &lt;- 5000 nBurnin &lt;- 1000 nChains &lt;- 2 thinRate &lt;- 5 start &lt;- Sys.time() Rmodel &lt;- nimbleModel( code = hmm.phiT_pT, constants = myConstants, data = myData, inits = initialValues(), calculate = FALSE ) conf &lt;- configureMCMC( Rmodel, monitors = parametersToSave ) Rmcmc &lt;- buildMCMC(conf, useConjugacy = FALSE) Cmodel &lt;- compileNimble(Rmodel) Cmcmc &lt;- compileNimble(Rmcmc, project = Rmodel) mcmc.phiT_pT &lt;- runMCMC( Cmcmc, niter = nIter, nburnin = nBurnin, thin = thinRate, nchains = nChains ) end &lt;- Sys.time() elapsed_phiT_pT &lt;- end - start toSave &lt;- list( mcmc = mcmc.phiT_pT, elapsed = elapsed_phiT_pT, name = &quot;phiT_pT&quot;, myConstants = myConstants, nIter = nIter, nBurnin = nBurnin, thinRate = thinRate, nSeasons = nSeasons, nCohorts = nCohorts, nChains = nChains ) save(toSave, file = paste0(&#39;./models/cmrFlowWB/runsOut/mcmc_phiT_pT_&#39;, substr(end,1,13), &#39;.RData&#39;)) save(toSave, file = &#39;./models/cmrFlowWB/runsOut/mcmc_phiT_pT_mostRecent.RData&#39;) } else { load(&#39;./models/cmrFlowWB/runsOut/mcmc_phiT_pT_mostRecent.RData&#39;) } if (plotMCMCOutput) { #MCMCsummary(object = mcmc.phiT_pT, round = 2) MCMCplot(object = toSave$mcmc) priors &lt;- runif(toSave$nIter * toSave$nChains, 0, 1) MCMCtrace(object = toSave$mcmc, #ISB = FALSE, #exact = TRUE, #params = c(&quot;phi[1]&quot;, &quot;phi[2]&quot;, &quot;phi[3]&quot;, &quot;phi[4]&quot;, &quot;phi[5]&quot;, &quot;phi[9]&quot;, &quot;phi[10]&quot;, # &quot;p[1]&quot;, &quot;p[2]&quot;, &quot;p[3]&quot;, &quot;p[4]&quot;, &quot;p[5]&quot;), params = c(&quot;phi&quot;), pdf = FALSE, priors = priors) } 3.3.3 Model phiT_pT_isYOY Add structure for isYOY. This was important for the integrated growth/survival model, but probably not relevant here since we are estimating phi and p for each ageInSamples # Following https://oliviergimenez.github.io/bayesian-cr-workshop/worksheets/4_demo.html if (rerunSurivalModels) { y &lt;- eh$eh nSeasons &lt;- nrow(unique(eh$seasons)) nCohorts &lt;- nrow(unique(eh$cohorts)) hmm.phiT_pT_isYOY &lt;- nimbleCode({ delta[1] &lt;- 1 # Pr(alive t = 1) = 1 delta[2] &lt;- 0 # Pr(dead t = 1) = 0 for (i in 1:N){ for (t in 1:(T-1)){ # loop over time #logit(phi[t,i]) &lt;- betaPhi[t,isYOY[i,t]] # prior survival logit(phi[t,i]) &lt;- betaPhi[t] # prior survival gamma[1,1,t,i] &lt;- phi[t,i] # Pr(alive t -&gt; alive t+1) gamma[1,2,t,i] &lt;- 1 - phi[t,i] # Pr(alive t -&gt; dead t+1) gamma[2,1,t,i] &lt;- 0 # Pr(dead t -&gt; alive t+1) gamma[2,2,t,i] &lt;- 1 # Pr(dead t -&gt; dead t+1) logit(p[t,i]) &lt;- betaP[t] # prior detection omega[1,1,t,i] &lt;- 1 - p[t,i] # Pr(alive t -&gt; non-detected t) omega[1,2,t,i] &lt;- p[t,i] # Pr(alive t -&gt; detected t) omega[2,1,t,i] &lt;- 1 # Pr(dead t -&gt; non-detected t) omega[2,2,t,i] &lt;- 0 # Pr(dead t -&gt; detected t) } } for (y in 1:2){ # mean values betaPhiIsYOY[y] ~ dnorm(0,1) betaPIsYOY[y] ~ dnorm(0,1) } # isYOY = 1 for (t in 1:3){ betaPhi[t] ~ dnorm(betaPhiIsYOY[1], 1) betaP[t] ~ dnorm(betaPIsYOY[1], 1) } # isYOY = 2, older fish for (t in 4:(T-1)){ betaPhi[t] ~ dnorm(betaPhiIsYOY[2], 1) betaP[t] ~ dnorm(betaPIsYOY[2], 1) } # Backtransform for output for (y in 1:2){ betaPhiIsYOYOut[y] &lt;- 1/(1 + exp(-betaPhiIsYOY[y])) betaPIsYOYOut[y] &lt;- 1/(1 + exp(-betaPIsYOY[y])) } for (t in 1:(T-1)){ betaPhiOut[t] &lt;- 1/(1 + exp(-betaPhi[t])) betaPOut[t] &lt;- 1/(1 + exp(-betaP[t])) } # likelihood for (i in 1:N){ z[i,first[i]] ~ dcat(delta[1:2]) for (j in (first[i]+1):last[i]){ z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1, i]) y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1, i]) } } }) first &lt;- eh$first #apply(y, 1, function(x) min(which(x !=0))) last &lt;- eh$last myConstants &lt;- list(N = nrow(y), T = ncol(y), first = first, last = last, isYOY = eh$isYOY ) myData &lt;- list(y = y + 1) zinits &lt;- y + 1 # non-detection -&gt; alive zinits[zinits == 2] &lt;- 1 # dead -&gt; alive zInitsNA &lt;- ifelse(is.na(eh$isYOY), NA, 1) initialValues &lt;- function() list( phi = array(runif((myConstants$T - 1) * myConstants$N, 0, 1),c((myConstants$T - 1), myConstants$N)), p = array(runif((myConstants$T - 1) * myConstants$N, 0, 1),c((myConstants$T - 1), myConstants$N)), z = zInitsNA, betaPhi = array(runif((myConstants$T - 1), 0, 1),c((myConstants$T - 1))), betaP = array(runif((myConstants$T - 1), 0, 1),c((myConstants$T - 1))), betaPhiIsYOY = array(runif(2, 0, 1),c(2)), betaPIsYOY = array(runif(2, 0, 1),c(2)) ) parametersToSave &lt;- c(&quot;betaPhiOut&quot;, &quot;betaPOut&quot;, &quot;betaPIsYOYOut&quot;, &quot;betaPhiIsYOYOut&quot;) nIter &lt;- 5000 nBurnin &lt;- 1000 nChains &lt;- 2 thinRate &lt;- 5 start &lt;- Sys.time() Rmodel &lt;- nimbleModel( code = hmm.phiT_pT_isYOY, constants = myConstants, data = myData, inits = initialValues(), calculate = FALSE ) conf &lt;- configureMCMC( Rmodel, monitors = parametersToSave ) Rmcmc &lt;- buildMCMC(conf, useConjugacy = FALSE) Cmodel &lt;- compileNimble(Rmodel) Cmcmc &lt;- compileNimble(Rmcmc, project = Rmodel) mcmc.phiT_pT_isYOY &lt;- runMCMC( Cmcmc, niter = nIter, nburnin = nBurnin, thin = thinRate, nchains = nChains ) end &lt;- Sys.time() elapsed_phiT_pT_isYOY &lt;- end - start toSave &lt;- list( mcmc = mcmc.phiT_pT_isYOY, elapsed = elapsed_phiT_pT_isYOY, myConstants = myConstants, nIter = nIter, nBurnin = nBurnin, thinRate = thinRate, nSeasons = nSeasons, nCohorts = nCohorts, nChains = nChains ) save(toSave, file = paste0(&#39;./models/cmrFlowWB/runsOut/mcmc_phiT_pT_isYOY_&#39;, substr(end,1,13), &#39;.RData&#39;)) save(toSave, file = &#39;./models/cmrFlowWB/runsOut/mcmc_phiT_pT_isYOY_mostRecent.RData&#39;) } else { load(&#39;./models/cmrFlowWB/runsOut/mcmc_phiT_pT_isYOY_mostRecent.RData&#39;) } if(plotMCMCOutput) { MCMCsummary(object = toSave$mcmc, round = 2) MCMCplot(object = toSave$mcmc, params = &quot;betaPhiIsYOYOut&quot;) MCMCplot(object = toSave$mcmc, params = &quot;betaPhiOut&quot;) MCMCplot(object = toSave$mcmc, params = &quot;betaPOut&quot;)# priors &lt;- runif(toSave$nIter * toSave$nChains, 0, 1) MCMCtrace(object = toSave$mcmc, #ISB = FALSE, #exact = TRUE, params = c(&quot;betaPhiOut&quot;), pdf = FALSE, priors = priors) } 3.3.4 Model phiT_pT_cohort Phi and p vary by time and there is a cohort effect on phi #### Set up and run model # Following https://oliviergimenez.github.io/bayesian-cr-workshop/worksheets/4_demo.html if (rerunSurivalModels) { y &lt;- eh$eh nCohorts &lt;- nrow(unique(eh$cohorts)) hmm.phiT_pT_cohort &lt;- nimbleCode({ delta[1] &lt;- 1 # Pr(alive t = 1) = 1 delta[2] &lt;- 0 # Pr(dead t = 1) = 0 for (i in 1:N){ for (t in 1:(T-1)){ # loop over time logit(phi[t,i]) &lt;- betaPhi[t,cohort[i]] # prior survival gamma[1,1,t,i] &lt;- phi[t,i] # Pr(alive t -&gt; alive t+1) gamma[1,2,t,i] &lt;- 1 - phi[t,i] # Pr(alive t -&gt; dead t+1) gamma[2,1,t,i] &lt;- 0 # Pr(dead t -&gt; alive t+1) gamma[2,2,t,i] &lt;- 1 # Pr(dead t -&gt; dead t+1) logit(p[t,i]) &lt;- betaP[t,cohort[i]] # prior detection omega[1,1,t,i] &lt;- 1 - p[t,i] # Pr(alive t -&gt; non-detected t) omega[1,2,t,i] &lt;- p[t,i] # Pr(alive t -&gt; detected t) omega[2,1,t,i] &lt;- 1 # Pr(dead t -&gt; non-detected t) omega[2,2,t,i] &lt;- 0 # Pr(dead t -&gt; detected t) } } for (c in 1:nCohorts){ # mean values betaPhiCohort[c] ~ dnorm(0,1) betaPCohort[c] ~ dnorm(0,1) for (t in 1:(T-1)){ betaPhi[t,c] ~ dnorm(betaPhiCohort[c], 1) betaP[t,c] ~ dnorm(betaPCohort[c], 1) } } # back-transform for examining output for (c in 1:nCohorts){ betaPhiCohortOut[c] &lt;- 1/(1 + exp(-betaPhiCohort[c])) betaPCohortOut[c] &lt;- 1/(1 + exp(-betaPCohort[c])) for (t in 1:(T-1)){ betaPhiOut[t,c] &lt;- 1/(1 + exp(-betaPhi[t,c])) betaPOut[t,c] &lt;- 1/(1 + exp(-betaP[t,c])) } } # likelihood for (i in 1:N){ z[i,first[i]] ~ dcat(delta[1:2]) for (j in (first[i]+1):last[i]){ z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1, i]) y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1, i]) } } }) first &lt;- eh$first #apply(y, 1, function(x) min(which(x !=0))) last &lt;- eh$last cohort = ((eh$cohorts) - min(eh$cohorts) + 1)$cohort #can&#39;t be a data frame or tibble myConstants &lt;- list(N = nrow(y), T = ncol(y), first = first, last = last, cohort = cohort, nCohorts = nCohorts ) myData &lt;- list(y = y + 1) zinits &lt;- y + 1 # non-detection -&gt; alive zinits[zinits == 2] &lt;- 1 # dead -&gt; alive initialValues &lt;- function() list( phi = array(runif((myConstants$T - 1) * myConstants$N, 0, 1),c((myConstants$T - 1), myConstants$N)), p = array(runif((myConstants$T - 1) * myConstants$N, 0, 1),c((myConstants$T - 1), myConstants$N)), z = zinits, betaPhi = array(runif((myConstants$T - 1) * nCohorts, 0, 1),c((myConstants$T - 1), nCohorts)), betaP = array(runif((myConstants$T - 1) * nCohorts, 0, 1),c((myConstants$T - 1), nCohorts)), betaPhiCohort = array(runif(nCohorts, 0, 1),c(nCohorts)), betaPCohort = array(runif(nCohorts, 0, 1),c(nCohorts)) ) parametersToSave &lt;- c(&quot;betaPhiOut&quot;, &quot;betaPOut&quot;, &quot;betaPhiCohortOut&quot;, &quot;betaPCohortOut&quot;) nIter &lt;- 5000 nBurnin &lt;- 1000 nChains &lt;- 2 thinRate = 5 start &lt;- Sys.time() Rmodel &lt;- nimbleModel( code = hmm.phiT_pT_cohort, constants = myConstants, data = myData, inits = initialValues(), calculate = FALSE ) conf &lt;- configureMCMC( Rmodel, monitors = parametersToSave ) Rmcmc &lt;- buildMCMC(conf, useConjugacy = FALSE) Cmodel &lt;- compileNimble(Rmodel) Cmcmc &lt;- compileNimble(Rmcmc, project = Rmodel) mcmc.phiT_pT_cohort &lt;- runMCMC( Cmcmc, niter = nIter, nburnin = nBurnin, thin = thinRate, nchains = nChains ) end &lt;- Sys.time() elapsed_phiT_pT_cohort &lt;- end - start toSave &lt;- list( mcmc = mcmc.phiT_pT_cohort, elapsed = elapsed_phiT_pT_cohort, name = &quot;phiT_pT_cohort&quot;, myConstants = myConstants, nIter = nIter, nBurnin = nBurnin, thinRate = thinRate, nSeasons = nSeasons, nCohorts = nCohorts, nChains = nChains ) save(toSave, file = paste0(&#39;./models/cmrFlowWB/runsOut/mcmc_phiT_pT_cohort_&#39;, substr(end,1,13), &#39;.RData&#39;)) save(toSave, file = &#39;./models/cmrFlowWB/runsOut/mcmc_phiT_pT_cohort_mostRecent.RData&#39;) } else { load(&#39;./models/cmrFlowWB/runsOut/mcmc_phiT_pT_cohort_mostRecent.RData&#39;) } if(plotMCMCOutput) { MCMCplot(object = toSave$mcmc, params = c(&quot;betaPhiOut&quot;)) MCMCplot(object = toSave$mcmc, params = c(&quot;betaPhiCohortOut&quot;)) MCMCplot(object = toSave$mcmc, params = c(&quot;betaPCohortOut&quot;)) priors &lt;- runif(toSave$nIter * toSave$nChains, 0, 1) MCMCtrace(object = toSave$mcmc, #ISB = FALSE, #exact = TRUE, params = c(&quot;betaPhiCohortOut&quot;, &quot;betaPCohortOut&quot;), pdf = FALSE, priors = priors) } 3.3.4.1 Plot phi against flow data phiT_pT_cohort phiOut &lt;- MCMCsummary(toSave$mcmc, params = &#39;betaPhiOut&#39;) 3.3.5 Model phiT_pT_cohort_flow Add mean flow over the interval as a survival effect #### Set up and run model # Following https://oliviergimenez.github.io/bayesian-cr-workshop/worksheets/4_demo.html if (rerunSurivalModels) { y &lt;- eh$eh nCohorts &lt;- nrow(unique(eh$cohorts)) nSeasons &lt;- nrow(unique(eh$seasons)) seasonArray &lt;- c(3,4,1,2,3,4,1,2,3,4,1,2) hmm.phiT_pT_cohort_flow &lt;- nimbleCode({ delta[1] &lt;- 1 # Pr(alive t = 1) = 1 delta[2] &lt;- 0 # Pr(dead t = 1) = 0 for (i in 1:N){ for (t in 1:(T-1)){ # loop over time logit(phi[t,i]) &lt;- betaInt + betaPhi[t,cohort[i]] + betaFlow[1,season[t]] * flow[i,t] + betaFlow[2,season[t]] * flow[i,t] * flow[i,t] # prior survival gamma[1,1,t,i] &lt;- phi[t,i] # Pr(alive t -&gt; alive t+1) gamma[1,2,t,i] &lt;- 1 - phi[t,i] # Pr(alive t -&gt; dead t+1) gamma[2,1,t,i] &lt;- 0 # Pr(dead t -&gt; alive t+1) gamma[2,2,t,i] &lt;- 1 # Pr(dead t -&gt; dead t+1) logit(p[t,i]) &lt;- betaP[t,cohort[i]] # prior detection omega[1,1,t,i] &lt;- 1 - p[t,i] # Pr(alive t -&gt; non-detected t) omega[1,2,t,i] &lt;- p[t,i] # Pr(alive t -&gt; detected t) omega[2,1,t,i] &lt;- 1 # Pr(dead t -&gt; non-detected t) omega[2,2,t,i] &lt;- 0 # Pr(dead t -&gt; detected t) } } betaInt ~ dnorm(0,1) for (c in 1:nCohorts){ # mean values betaPhiCohort[c] ~ dnorm(0,1) betaPCohort[c] ~ dnorm(0,1) for (t in 1:(T-1)){ betaPhi[t,c] ~ dnorm(betaPhiCohort[c], 1) betaP[t,c] ~ dnorm(betaPCohort[c], 1) } } # back-transform for examining output for (c in 1:nCohorts){ betaPhiCohortOut[c] &lt;- 1/(1 + exp(-betaPhiCohort[c])) betaPCohortOut[c] &lt;- 1/(1 + exp(-betaPCohort[c])) for (t in 1:(T-1)){ betaPhiOut[t,c] &lt;- 1/(1 + exp(-betaPhi[t,c])) betaPOut[t,c] &lt;- 1/(1 + exp(-betaP[t,c])) } } for (s in 1:nSeasons){ betaFlow[1,s] ~ dnorm(0, 1) betaFlow[2,s] ~ dnorm(0, 1) } # likelihood for (i in 1:N){ z[i,first[i]] ~ dcat(delta[1:2]) for (j in (first[i]+1):(last[i])){ z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1, i]) y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1, i]) } } }) first &lt;- eh$first #apply(y, 1, function(x) min(which(x !=0))) last &lt;- eh$last cohort = ((eh$cohorts) - min(eh$cohorts) + 1)$cohort #can&#39;t be a data frame or tibble myConstants &lt;- list(N = nrow(y), T = ncol(y), first = first, last = last, cohort = cohort, nCohorts = nCohorts, season = seasonArray, #eh$seasons$season, flow = eh$flow ) myData &lt;- list(y = y + 1) zinits &lt;- y + 1 # non-detection -&gt; alive zinits[zinits == 2] &lt;- 1 # dead -&gt; alive zInitsNA &lt;- ifelse(is.na(eh$flow), NA, 1) initialValues &lt;- function() list( betaInt = rnorm(1, 0, 1), phi = array(runif((myConstants$T - 1) * myConstants$N, 0, 1),c((myConstants$T - 1), myConstants$N)), p = array(runif((myConstants$T - 1) * myConstants$N, 0, 1),c((myConstants$T - 1), myConstants$N)), z = zInitsNA, betaPhi = array(runif((myConstants$T - 1) * nCohorts, 0, 1),c((myConstants$T - 1), nCohorts)), betaP = array(runif((myConstants$T - 1) * nCohorts, 0, 1),c((myConstants$T - 1), nCohorts)), betaPhiCohort = array(runif(nCohorts, 0, 1),c(nCohorts)), betaPCohort = array(runif(nCohorts, 0, 1),c(nCohorts)), betaFlow = array(rnorm(2 * 4, 0, 1), c(2, 4)) ) parametersToSave &lt;- c(&quot;betaInt&quot;, &quot;betaPhi&quot;, &quot;betaP&quot;, &quot;betaPhiCohort&quot;, &quot;betaPCohort&quot;, &quot;betaPhiOut&quot;, &quot;betaPOut&quot;, &quot;betaPhiCohortOut&quot;, &quot;betaPCohortOut&quot;, &quot;betaFlow&quot;) nIter &lt;- 20000 nBurnin &lt;- 10000 nChains &lt;- 2 thinRate &lt;- 5 start = Sys.time() Rmodel &lt;- nimbleModel( code = hmm.phiT_pT_cohort_flow, constants = myConstants, data = myData, inits = initialValues(), calculate = FALSE ) conf &lt;- configureMCMC( Rmodel, monitors = parametersToSave ) Rmcmc &lt;- buildMCMC(conf, useConjugacy = FALSE) Cmodel &lt;- compileNimble(Rmodel) Cmcmc &lt;- compileNimble(Rmcmc, project = Rmodel) mcmc.phiT_pT_cohort_flow &lt;- runMCMC( Cmcmc, niter = nIter, nburnin = nBurnin, thin = thinRate, nchains = nChains ) end &lt;- Sys.time() elapsed_phiT_pT_cohort_flow &lt;- end - start toSave &lt;- list( mcmc = mcmc.phiT_pT_cohort_flow, elapsed = elapsed_phiT_pT_cohort_flow, name = &quot;phiT_pT_cohort_flow&quot;, myConstants = myConstants, nIter = nIter, nBurnin = nBurnin, thinRate = thinRate, nSeasons = nSeasons, nCohorts = nCohorts, nChains = nChains ) save(toSave, file = paste0(&#39;./models/cmrFlowWB/runsOut/mcmc_phiT_pT_cohort_flow_&#39;, substr(end,1,13), &#39;.RData&#39;)) save(toSave, file = &#39;./models/cmrFlowWB/runsOut/mcmc_phiT_pT_cohort_flow_mostRecent.RData&#39;) } else { load(&#39;./models/cmrFlowWB/runsOut/mcmc_phiT_pT_cohort_flow_mostRecent.RData&#39;) } # could consider forward algo to speed up convergence (https://oliviergimenez.github.io/banana-book/hmmcapturerecapture.html#nimble-implementation-1) if(plotMCMCOutput) { #MCMCsummary(object = toSave$mcmc, round = 2) #MCMCplot(object = mcmc.phiT_pT_cohort_flow, params = &quot;betaPhiOut&quot;) MCMCplot(object = toSave$mcmc, params = &quot;betaFlow&quot;)# MCMCplot(object = toSave$mcmc, params = c(&quot;betaPhiCohortOut&quot;)) MCMCplot(object = toSave$mcmc, params = c(&quot;betaPCohortOut&quot;)) priors &lt;- runif(toSave$nIter * toSave$nChains, 0, 1) MCMCtrace(object = toSave$mcmc, #ISB = FALSE, #exact = TRUE, params = c(&quot;betaPhiCohortOut&quot;), pdf = FALSE, priors = priors) MCMCtrace(object = toSave$mcmc, #ISB = FALSE, #exact = TRUE, params = c(&quot;betaFlow&quot;), pdf = FALSE, priors = priors) } # run more iterations, if necessary # nIterAdd &lt;- 5000 # Cmcmc$run(nIterAdd, reset = FALSE) # more_samples &lt;- as.matrix(Cmcmc$mvSamples) # # MCMCtrace(object = more_samples, # #ISB = FALSE, # #exact = TRUE, # params = c(&quot;betaFlow&quot;), # pdf = FALSE, # priors = priors) 3.3.5.1 Get flow effect estimates Flow effects fixed across cohorts # betaInt + # betaPhi[t,cohort[i]] + # betaFlow[1,season[t]] * flow[i,t] + # betaFlow[2,season[t]] * flow[i,t] * flow[i,t] getPredictionsFlow &lt;- function(mcmc, everyNIters = 10, flowStep = 0.5){ ## betaInt predictorsBetaInt &lt;- expand.grid( iter = seq(1, dim(mcmc$chain1)[1], everyNIters) ) for(i in 1:nrow(predictorsBetaInt)){ predictorsBetaInt$betaInt[i] &lt;- mcmc$chain1[[ predictorsBetaInt[i, &quot;iter&quot;], &quot;betaInt&quot; ]] } ## betaFlow predictorsBetaFlow &lt;- expand.grid( iter = seq(1, dim(mcmc$chain1)[1], everyNIters), season = 1:toSave$nSeasons ) for(i in 1:nrow(predictorsBetaFlow)){ predictorsBetaFlow$betaFlow1[i] &lt;- mcmc$chain1[[predictorsBetaFlow[i, &quot;iter&quot;], paste0(&quot;betaFlow[1, &quot;, predictorsBetaFlow[i, &quot;season&quot;], &quot;]&quot;) ]] predictorsBetaFlow$betaFlow2[i] &lt;- mcmc$chain1[[predictorsBetaFlow[i, &quot;iter&quot;], paste0(&quot;betaFlow[2, &quot;, predictorsBetaFlow[i, &quot;season&quot;], &quot;]&quot;) ]] } ## betaPhi predictorsBetaPhi &lt;- expand.grid( iter = seq(1, dim(mcmc$chain1)[1], everyNIters), cohort = 1:toSave$nCohorts ) for(i in 1:nrow(predictorsBetaPhi)){ predictorsBetaPhi$betaPhi[i] &lt;- mcmc$chain1[[predictorsBetaPhi[i, &quot;iter&quot;], paste0(&quot;betaPhiCohort[&quot;, predictorsBetaPhi[i, &quot;cohort&quot;], &quot;]&quot;) ]] } predictorsAll &lt;- expand.grid( iter = seq(1, dim(mcmc$chain1)[1], everyNIters), cohort = 1:toSave$nCohorts, season = 1:toSave$nSeasons, flow = seq(-1.5, 1.5, flowStep) ) preds &lt;- predictorsAll %&gt;% left_join(predictorsBetaInt) %&gt;% left_join(predictorsBetaFlow) %&gt;% left_join(predictorsBetaPhi) %&gt;% mutate(predPhi = plogis(betaInt + betaPhi + betaFlow1 * flow + betaFlow2 * flow^2)) return(preds) } predFlow &lt;- getPredictionsFlow(toSave$mcmc, everyNIters = 2) 3.3.5.2 Plot flow predictions phiT_pT_cohort_flow ggplot(predFlow, aes(flow, predPhi, group = iter)) + geom_line(alpha = 0.025) + facet_grid(season ~ cohort) # ggplot(predFlow %&gt;% filter(season ==1, cohort == 6), aes(flow, predPhi, group = iter)) + # geom_line(alpha = 0.5) + # facet_grid(cohort ~ season) # # ggplot(predFlow %&gt;% filter(cohort == 3), aes(flow, predPhi, group = iter)) + # geom_line(alpha = 0.1) + # facet_wrap( ~ season) # # ggplot(predFlow %&gt;% filter(season ==1), aes(flow, predPhi, group = iter)) + # geom_line(alpha = 0.1) + # facet_wrap(~ cohort) 3.3.6 Model phiT_pT_cohort_flowCohort Flow effects vary by cohort #### Set up and run model # Following https://oliviergimenez.github.io/bayesian-cr-workshop/worksheets/4_demo.html if (rerunSurivalModels) { y &lt;- eh$eh nCohorts &lt;- nrow(unique(eh$cohorts)) nSeasons &lt;- nrow(unique(eh$seasons)) seasonArray &lt;- c(3,4,1,2,3,4,1,2,3,4,1,2) hmm.phiT_pT_cohort_flowCohort &lt;- nimbleCode({ delta[1] &lt;- 1 # Pr(alive t = 1) = 1 delta[2] &lt;- 0 # Pr(dead t = 1) = 0 for (i in 1:N){ for (t in 1:(T-1)){ # loop over time logit(phi[t,i]) &lt;- betaInt + betaPhi[t,cohort[i]] + betaFlow[1,season[t],cohort[i]] * flow[i,t] + betaFlow[2,season[t],cohort[i]] * flow[i,t] * flow[i,t] # prior survival gamma[1,1,t,i] &lt;- phi[t,i] # Pr(alive t -&gt; alive t+1) gamma[1,2,t,i] &lt;- 1 - phi[t,i] # Pr(alive t -&gt; dead t+1) gamma[2,1,t,i] &lt;- 0 # Pr(dead t -&gt; alive t+1) gamma[2,2,t,i] &lt;- 1 # Pr(dead t -&gt; dead t+1) logit(p[t,i]) &lt;- betaP[t,cohort[i]] # prior detection omega[1,1,t,i] &lt;- 1 - p[t,i] # Pr(alive t -&gt; non-detected t) omega[1,2,t,i] &lt;- p[t,i] # Pr(alive t -&gt; detected t) omega[2,1,t,i] &lt;- 1 # Pr(dead t -&gt; non-detected t) omega[2,2,t,i] &lt;- 0 # Pr(dead t -&gt; detected t) } } betaInt ~ dnorm(0,1) for (c in 1:nCohorts){ # mean values betaPhiCohort[c] ~ dnorm(0,1) betaPCohort[c] ~ dnorm(0,1) for (t in 1:(T-1)){ betaPhi[t,c] ~ dnorm(betaPhiCohort[c], 1) betaP[t,c] ~ dnorm(betaPCohort[c], 1) } } # back-transform for examining output for (c in 1:nCohorts){ betaPhiCohortOut[c] &lt;- 1/(1 + exp(-betaPhiCohort[c])) betaPCohortOut[c] &lt;- 1/(1 + exp(-betaPCohort[c])) for (t in 1:(T-1)){ betaPhiOut[t,c] &lt;- 1/(1 + exp(-betaPhi[t,c])) betaPOut[t,c] &lt;- 1/(1 + exp(-betaP[t,c])) } } for (s in 1:nSeasons){ for (c in 1:nCohorts){ betaFlow[1,s,c] ~ dnorm(0, 1) betaFlow[2,s,c] ~ dnorm(0, 1) } } # likelihood for (i in 1:N){ z[i,first[i]] ~ dcat(delta[1:2]) for (j in (first[i]+1):(last[i])){ z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1, i]) y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1, i]) } } }) first &lt;- eh$first #apply(y, 1, function(x) min(which(x !=0))) last &lt;- eh$last cohort = ((eh$cohorts) - min(eh$cohorts) + 1)$cohort #can&#39;t be a data frame or tibble myConstants &lt;- list(N = nrow(y), T = ncol(y), first = first, last = last, cohort = cohort, nCohorts = nCohorts, season = seasonArray, #eh$seasons$season, flow = eh$flow ) myData &lt;- list(y = y + 1) zinits &lt;- y + 1 # non-detection -&gt; alive zinits[zinits == 2] &lt;- 1 # dead -&gt; alive zInitsNA &lt;- ifelse(is.na(eh$flow), NA, 1) initialValues &lt;- function() list( betaInt = rnorm(1, 0, 1), phi = array(runif((myConstants$T - 1) * myConstants$N, 0, 1),c((myConstants$T - 1), myConstants$N)), p = array(runif((myConstants$T - 1) * myConstants$N, 0, 1),c((myConstants$T - 1), myConstants$N)), z = zInitsNA, betaPhi = array(runif((myConstants$T - 1) * nCohorts, 0, 1),c((myConstants$T - 1), nCohorts)), betaP = array(runif((myConstants$T - 1) * nCohorts, 0, 1),c((myConstants$T - 1), nCohorts)), betaPhiCohort = array(runif(nCohorts, 0, 1),c(nCohorts)), betaPCohort = array(runif(nCohorts, 0, 1),c(nCohorts)), betaFlow = array(rnorm(2 * 4 * nCohorts, 0, 1), c(2, 4, nCohorts)) ) parametersToSave &lt;- c(&quot;betaInt&quot;, &quot;betaPhi&quot;, &quot;betaP&quot;, &quot;betaPhiCohort&quot;, &quot;betaPCohort&quot;, &quot;betaPhiOut&quot;, &quot;betaPOut&quot;, &quot;betaPhiCohortOut&quot;, &quot;betaPCohortOut&quot;, &quot;betaFlow&quot;) nIter &lt;- 20000 nBurnin &lt;- 10000 nChains &lt;- 2 thinRate &lt;- 5 start = Sys.time() Rmodel &lt;- nimbleModel( code = hmm.phiT_pT_cohort_flowCohort, constants = myConstants, data = myData, inits = initialValues(), calculate = FALSE ) conf &lt;- configureMCMC( Rmodel, monitors = parametersToSave ) Rmcmc &lt;- buildMCMC(conf, useConjugacy = FALSE) Cmodel &lt;- compileNimble(Rmodel) Cmcmc &lt;- compileNimble(Rmcmc, project = Rmodel) mcmc.phiT_pT_cohort_flowCohort &lt;- runMCMC( Cmcmc, niter = nIter, nburnin = nBurnin, thin = thinRate, nchains = nChains ) end &lt;- Sys.time() elapsed_phiT_pT_cohort_flowCohort &lt;- end - start toSave &lt;- list( mcmc = mcmc.phiT_pT_cohort_flowCohort, elapsed = elapsed_phiT_pT_cohort_flowCohort, name = &quot;phiT_pT_cohort_flowCohort&quot;, myConstants = myConstants, nIter = nIter, nBurnin = nBurnin, thinRate = thinRate, nSeasons = nSeasons, nCohorts = nCohorts, nChains = nChains ) save(toSave, file = paste0(&#39;./models/cmrFlowWB/runsOut/mcmc_phiT_pT_cohort_flowCohort_&#39;, substr(end,1,13), &#39;.RData&#39;)) save(toSave, file = &#39;./models/cmrFlowWB/runsOut/mcmc_phiT_pT_cohort_flowCohort_mostRecent.RData&#39;) } else { load(&#39;./models/cmrFlowWB/runsOut/mcmc_phiT_pT_cohort_flowCohort_mostRecent.RData&#39;) } # could consider forward algo to speed up convergence (https://oliviergimenez.github.io/banana-book/hmmcapturerecapture.html#nimble-implementation-1) if(plotMCMCOutput) { #MCMCsummary(object = mcmc.phiT_pT_cohort_flow, round = 2) #MCMCplot(object = mcmc.phiT_pT_cohort_flow, params = &quot;betaPhiOut&quot;) MCMCplot(object = toSave$mcmc, params = &quot;betaFlow&quot;)# MCMCplot(object = toSave$mcmc, params = c(&quot;betaPhiCohortOut&quot;)) MCMCplot(object = toSave$mcmc, params = c(&quot;betaPCohortOut&quot;)) priors &lt;- runif(toSave$nIter * toSave$nChains, 0, 1) MCMCtrace(object = toSave$mcmc, #ISB = FALSE, #exact = TRUE, params = c(&quot;betaPhiCohortOut&quot;), pdf = FALSE, priors = priors) MCMCtrace(object = toSave$mcmc, #ISB = FALSE, #exact = TRUE, params = c(&quot;betaFlow&quot;), pdf = FALSE, priors = priors) } # run more iterations, if necessary # nIterAdd &lt;- 5000 # Cmcmc$run(nIterAdd, reset = FALSE) # more_samples &lt;- as.matrix(Cmcmc$mvSamples) # # MCMCtrace(object = more_samples, # #ISB = FALSE, # #exact = TRUE, # params = c(&quot;betaFlow&quot;), # pdf = FALSE, # priors = priors) 3.3.6.1 Get flow effect estimates Flow effects vary across cohorts # betaInt + # betaPhi[t,cohort[i]] + # betaFlow[1,season[t],cohort[i]] * flow[i,t] + # betaFlow[2,season[t],cohort[i]] * flow[i,t] * flow[i,t] # load current flow model #load(&quot;C:/Users/bletcher/OneDrive - DOI/projects/westBrook-book/models/cmrFlowWB/runsOut/mcmc_phiT_pT_cohort_flow_2022-05-12 10.RData&quot;) getPredictionsFlowCohort &lt;- function(toSave, everyNIters = 10, flowStep = 0.5){ mcmc &lt;- toSave$mcmc ## betaInt predictorsBetaInt &lt;- expand.grid( iter = seq(1, dim(mcmc$chain1)[1], everyNIters) ) for(i in 1:nrow(predictorsBetaInt)){ predictorsBetaInt$betaInt[i] &lt;- mcmc$chain1[[ predictorsBetaInt[i, &quot;iter&quot;], &quot;betaInt&quot; ]] } ## betaFlow predictorsBetaFlow &lt;- expand.grid( iter = seq(1, dim(mcmc$chain1)[1], everyNIters), season = 1:toSave$nSeasons, cohort = 1:toSave$nCohorts ) for(i in 1:nrow(predictorsBetaFlow)){ predictorsBetaFlow$betaFlow1[i] &lt;- mcmc$chain1[[predictorsBetaFlow[i, &quot;iter&quot;], paste0(&quot;betaFlow[1, &quot;, predictorsBetaFlow[i, &quot;season&quot;], &quot;, &quot;, predictorsBetaFlow[i, &quot;cohort&quot;], &quot;]&quot;) ]] predictorsBetaFlow$betaFlow2[i] &lt;- mcmc$chain1[[predictorsBetaFlow[i, &quot;iter&quot;], paste0(&quot;betaFlow[2, &quot;, predictorsBetaFlow[i, &quot;season&quot;], &quot;, &quot;, predictorsBetaFlow[i, &quot;cohort&quot;], &quot;]&quot;) ]] } ## betaPhi predictorsBetaPhi &lt;- expand.grid( iter = seq(1, dim(mcmc$chain1)[1], everyNIters), cohort = 1:toSave$nCohorts ) # this step is very slow for some reason...... for(i in 1:nrow(predictorsBetaPhi)){ predictorsBetaPhi$betaPhi[i] &lt;- mcmc$chain1[[predictorsBetaPhi[i, &quot;iter&quot;], paste0(&quot;betaPhiCohort[&quot;, predictorsBetaPhi[i, &quot;cohort&quot;], &quot;]&quot;) ]] } predictorsAll &lt;- expand.grid( iter = seq(1, dim(mcmc$chain1)[1], everyNIters), cohort = 1:toSave$nCohorts, season = 1:toSave$nSeasons, flow = seq(-1.5, 1.5, flowStep) ) preds &lt;- predictorsAll %&gt;% left_join(predictorsBetaInt) %&gt;% left_join(predictorsBetaFlow) %&gt;% left_join(predictorsBetaPhi) %&gt;% mutate(predPhi = plogis(betaInt + betaPhi + betaFlow1 * flow + betaFlow2 * flow^2)) return(preds) } predFlowCohort &lt;- getPredictionsFlowCohort(toSave, everyNIters = 2) 3.3.6.2 Plot flow predictions phiT_pT_cohort_flowCohort ggplot(predFlowCohort, aes(flow, predPhi, group = iter)) + geom_line(alpha = 0.025) + facet_grid(season ~ cohort) # ggplot(predFlowCohort %&gt;% filter(season ==1, cohort == 6), aes(flow, predPhi, group = iter)) + # geom_line(alpha = 0.5) + # facet_grid(cohort ~ season) # # ggplot(predFlowCohort %&gt;% filter(cohort == 3), aes(flow, predPhi, group = iter)) + # geom_line(alpha = 0.1) + # facet_wrap( ~ season) # # ggplot(predFlowCohort %&gt;% filter(season ==1), aes(flow, predPhi, group = iter)) + # geom_line(alpha = 0.1) + # facet_wrap(~ cohort) 3.3.7 Model phiT_pT_cohort_flowCohortHier Flow effects vary by cohort, hierarchical across cohorts #### Set up and run model # Following https://oliviergimenez.github.io/bayesian-cr-workshop/worksheets/4_demo.html if (rerunSurivalModels) { y &lt;- eh$eh nCohorts &lt;- nrow(unique(eh$cohorts)) nSeasons &lt;- nrow(unique(eh$seasons)) seasonArray &lt;- c(3,4,1,2,3,4,1,2,3,4,1,2) hmm.phiT_pT_cohort_flowCohortHier &lt;- nimbleCode({ delta[1] &lt;- 1 # Pr(alive t = 1) = 1 delta[2] &lt;- 0 # Pr(dead t = 1) = 0 for (i in 1:N){ for (t in 1:(T-1)){ # loop over time logit(phi[t,i]) &lt;- betaInt + betaPhi[t,cohort[i]] + betaFlow[1,season[t],cohort[i]] * flow[i,t] + betaFlow[2,season[t],cohort[i]] * flow[i,t] * flow[i,t] # prior survival gamma[1,1,t,i] &lt;- phi[t,i] # Pr(alive t -&gt; alive t+1) gamma[1,2,t,i] &lt;- 1 - phi[t,i] # Pr(alive t -&gt; dead t+1) gamma[2,1,t,i] &lt;- 0 # Pr(dead t -&gt; alive t+1) gamma[2,2,t,i] &lt;- 1 # Pr(dead t -&gt; dead t+1) logit(p[t,i]) &lt;- betaP[t,cohort[i]] # prior detection omega[1,1,t,i] &lt;- 1 - p[t,i] # Pr(alive t -&gt; non-detected t) omega[1,2,t,i] &lt;- p[t,i] # Pr(alive t -&gt; detected t) omega[2,1,t,i] &lt;- 1 # Pr(dead t -&gt; non-detected t) omega[2,2,t,i] &lt;- 0 # Pr(dead t -&gt; detected t) } } betaInt ~ dnorm(0,1) betaFlowTop[1] ~ dnorm(0,1) betaFlowTop[2] ~ dnorm(0,1) for (c in 1:nCohorts){ # mean values betaPhiCohort[c] ~ dnorm(0,1) betaPCohort[c] ~ dnorm(0,1) betaFlowCohort[1,c] ~ dnorm(betaFlowTop[1],1) betaFlowCohort[2,c] ~ dnorm(betaFlowTop[2],1) for (t in 1:(T-1)){ betaPhi[t,c] ~ dnorm(betaPhiCohort[c],1) betaP[t,c] ~ dnorm(betaPCohort[c],1) } } # back-transform for examining output for (c in 1:nCohorts){ betaPhiCohortOut[c] &lt;- 1/(1 + exp(-betaPhiCohort[c])) betaPCohortOut[c] &lt;- 1/(1 + exp(-betaPCohort[c])) for (t in 1:(T-1)){ betaPhiOut[t,c] &lt;- 1/(1 + exp(-betaPhi[t,c])) betaPOut[t,c] &lt;- 1/(1 + exp(-betaP[t,c])) } } for (s in 1:nSeasons){ for (c in 1:nCohorts){ betaFlow[1,s,c] ~ dnorm(betaFlowCohort[1,c],1) betaFlow[2,s,c] ~ dnorm(betaFlowCohort[2,c],1) } } # likelihood for (i in 1:N){ z[i,first[i]] ~ dcat(delta[1:2]) for (j in (first[i]+1):(last[i])){ z[i,j] ~ dcat(gamma[z[i,j-1], 1:2, j-1, i]) y[i,j] ~ dcat(omega[z[i,j], 1:2, j-1, i]) } } }) first &lt;- eh$first #apply(y, 1, function(x) min(which(x !=0))) last &lt;- eh$last cohort = ((eh$cohorts) - min(eh$cohorts) + 1)$cohort #can&#39;t be a data frame or tibble myConstants &lt;- list(N = nrow(y), T = ncol(y), first = first, last = last, cohort = cohort, nCohorts = nCohorts, season = seasonArray, #eh$seasons$season, flow = eh$flow ) myData &lt;- list(y = y + 1) zinits &lt;- y + 1 # non-detection -&gt; alive zinits[zinits == 2] &lt;- 1 # dead -&gt; alive zInitsNA &lt;- ifelse(is.na(eh$flow), NA, 1) initialValues &lt;- function() list( betaInt = rnorm(1, 0, 1), phi = array(runif((myConstants$T - 1) * myConstants$N, 0, 1),c((myConstants$T - 1), myConstants$N)), p = array(runif((myConstants$T - 1) * myConstants$N, 0, 1),c((myConstants$T - 1), myConstants$N)), z = zInitsNA, betaPhi = array(runif((myConstants$T - 1) * nCohorts, 0, 1),c((myConstants$T - 1), nCohorts)), betaP = array(runif((myConstants$T - 1) * nCohorts, 0, 1),c((myConstants$T - 1), nCohorts)), betaPhiCohort = array(runif(nCohorts, 0, 1),c(nCohorts)), betaPCohort = array(runif(nCohorts, 0, 1),c(nCohorts)), betaFlow = array(rnorm(2 * 4 * nCohorts, 0, 1), c(2, 4, nCohorts)), betaFlowCohort = array(rnorm(2 * nCohorts, 0, 1), c(2, nCohorts)), betaFlowTop = rnorm(2, 0, 1) ) parametersToSave &lt;- c(&quot;betaInt&quot;, &quot;betaPhi&quot;, &quot;betaP&quot;, &quot;betaPhiCohort&quot;, &quot;betaPCohort&quot;, &quot;betaPhiOut&quot;, &quot;betaPOut&quot;, &quot;betaPhiCohortOut&quot;, &quot;betaPCohortOut&quot;, &quot;betaFlow&quot;, &quot;betaFlowCohort&quot;, &quot;betaFlowTop&quot;) nIter &lt;- 30000 nBurnin &lt;- 15000 nChains &lt;- 2 thinRate &lt;- 5 start = Sys.time() Rmodel &lt;- nimbleModel( code = hmm.phiT_pT_cohort_flowCohortHier, constants = myConstants, data = myData, inits = initialValues(), calculate = FALSE ) conf &lt;- configureMCMC( Rmodel, monitors = parametersToSave ) Rmcmc &lt;- buildMCMC(conf, useConjugacy = FALSE) Cmodel &lt;- compileNimble(Rmodel) Cmcmc &lt;- compileNimble(Rmcmc, project = Rmodel) mcmc.phiT_pT_cohort_flowCohortHier &lt;- runMCMC( Cmcmc, niter = nIter, nburnin = nBurnin, thin = thinRate, nchains = nChains ) end &lt;- Sys.time() elapsed_phiT_pT_cohort_flowCohortHier &lt;- end - start toSave &lt;- list( mcmc = mcmc.phiT_pT_cohort_flowCohortHier, elapsed = elapsed_phiT_pT_cohort_flowCohortHier, name = &quot;phiT_pT_cohort_flowCohortHier&quot;, myConstants = myConstants, nIter = nIter, nBurnin = nBurnin, thinRate = thinRate, nSeasons = nSeasons, nCohorts = nCohorts, nChains = nChains ) save(toSave, file = paste0(&#39;./models/cmrFlowWB/runsOut/mcmc_phiT_pT_cohort_flowCohortHier_&#39;, substr(end,1,13), &#39;.RData&#39;)) save(toSave, file = &#39;./models/cmrFlowWB/runsOut/mcmc_phiT_pT_cohort_flowCohortHier_mostRecent.RData&#39;) } else { load(&#39;./models/cmrFlowWB/runsOut/mcmc_phiT_pT_cohort_flowCohortHier_mostRecent.RData&#39;) } # could consider forward algo to speed up convergence (https://oliviergimenez.github.io/banana-book/hmmcapturerecapture.html#nimble-implementation-1) if(plotMCMCOutput) { #MCMCsummary(object = mcmc.phiT_pT_cohort_flowHier, round = 2) #MCMCplot(object = mcmc.phiT_pT_cohort_flowHier, params = &quot;betaPhiOut&quot;) MCMCplot(object = toSave$mcmc, params = &quot;betaFlowTop&quot;) MCMCplot(object = toSave$mcmc, params = &quot;betaFlow&quot;)# MCMCplot(object = toSave$mcmc, params = c(&quot;betaPhiCohortOut&quot;)) MCMCplot(object = toSave$mcmc, params = c(&quot;betaPCohortOut&quot;)) MCMCplot(object = toSave$mcmc, params = c(&quot;betaFlowCohort&quot;)) priors &lt;- runif(toSave$nIter * toSave$nChains, 0, 1) MCMCtrace(object = toSave$mcmc, #ISB = FALSE, #exact = TRUE, params = c(&quot;betaFlowTop&quot;), pdf = FALSE, priors = priors) MCMCtrace(object = toSave$mcmc, #ISB = FALSE, #exact = TRUE, params = c(&quot;betaPhiCohortOut&quot;), pdf = FALSE, priors = priors) MCMCtrace(object = toSave$mcmc, #ISB = FALSE, #exact = TRUE, params = c(&quot;betaFlow&quot;), pdf = FALSE, priors = priors) } # run more iterations, if necessary # nIterAdd &lt;- 5000 # Cmcmc$run(nIterAdd, reset = FALSE) # more_samples &lt;- as.matrix(Cmcmc$mvSamples) # # MCMCtrace(object = more_samples, # #ISB = FALSE, # #exact = TRUE, # params = c(&quot;betaFlow&quot;), # pdf = FALSE, # priors = priors) 3.3.7.1 Get flow effect estimates Flow effects vary across cohorts - hierarchical # betaInt + # betaPhi[t,cohort[i]] + # betaFlow[1,season[t],cohort[i]] * flow[i,t] + # betaFlow[2,season[t],cohort[i]] * flow[i,t] * flow[i,t] load(&#39;./models/cmrFlowWB/runsOut/mcmc_phiT_pT_cohort_flowCohortHier_mostRecent.RData&#39;) predFlowCohortHier &lt;- getPredictionsFlowCohort(toSave, everyNIters = 2) 3.3.7.2 Plot predictions ggplot(predFlowCohortHier, aes(flow, predPhi, group = iter)) + geom_line(alpha = 0.025) + facet_grid(season ~ cohort) # ggplot(predFlowCohortHier %&gt;% filter(season ==1, cohort == 6), aes(flow, predPhi, group = iter)) + # geom_line(alpha = 0.5) + # facet_grid(cohort ~ season) # # ggplot(predFlowCohortHier %&gt;% filter(cohort == 3), aes(flow, predPhi, group = iter)) + # geom_line(alpha = 0.1) + # facet_wrap( ~ season) # # ggplot(predFlowCohortHier %&gt;% filter(season ==3), aes(flow, predPhi, group = iter)) + # geom_line(alpha = 0.1) + # facet_wrap(~ cohort) 3.3.7.3 BetaflowTop predictions getPredictionsFlowTop &lt;- function(toSave, everyNIters = 10, flowStep = 0.5){ mcmc &lt;- toSave$mcmc ## betaFlow predictorsBetaFlowTop &lt;- expand.grid( iter = seq(1, dim(mcmc$chain1)[1], everyNIters), var = 1:2, flow = seq(-1.5, 1.5, flowStep) ) for(i in 1:nrow(predictorsBetaFlowTop)){ predictorsBetaFlowTop$betaFlowTop1[i] &lt;- mcmc$chain1[[predictorsBetaFlowTop[i, &quot;iter&quot;], 1 ]] predictorsBetaFlowTop$betaFlowTop2[i] &lt;- mcmc$chain1[[predictorsBetaFlowTop[i, &quot;iter&quot;], 2 ]] } preds &lt;- predictorsBetaFlowTop %&gt;% mutate(predPhi = plogis(betaFlowTop1 * flow + betaFlowTop2 * flow * flow)) return(preds) } predBetaFlowTop &lt;- getPredictionsFlowTop(toSave, everyNIters = 10) ggplot(predBetaFlowTop, aes(flow, predPhi, group = iter)) + geom_line() #+ #facet_wrap(~iter) ggplot(predBetaFlowTop, aes(betaFlowTop1, betaFlowTop2)) + geom_point() 3.3.8 Compare models #data.frame(model = c(&quot;(phi,p)&quot;, # &quot;(phit,pt)&quot;), # WAIC = c(mcmc.phi_p, # mcmc.phiT_pT)) "],["final-words.html", "Chapter 4 Final Words", " Chapter 4 Final Words We have finished a nice book. "],["references.html", "References", " References Some references related to the West Brook study. Will need to update and sort. (From Bens Mendelay, searched for “West brook” and deleted a few refs). Grader, M., and Letcher, B. 2006. Diel and seasonal gut fullness and prey composition of Atlantic salmon parr in the west brook. J. Freshw. Ecol. 21(3): 503–517. Armstrong, J.D., and Nislow, K.H. 2012. Modelling approaches for relating effects of change in river flow to populations of Atlantic salmon and brown trout. Fish. Manag. Ecol. 19(6): 527–536. doi:10.1111/j.1365-2400.2011.00835.x. Letcher, B.H., Dubreuil, T.L., O’Donnell, M.J., Obedzinski, M., Griswold, K., and Nislow, K.H. 2004. Long-term consequences of variation in timing and manner of fry introduction on juvenile Atlantic salmon (Salmo salar) growth, survival, and life-history expression. Can. J. Fish. Aquat. Sci. 61(12): 2288–2301. doi:10.1139/f04-214. Letcher, B.H., and Gries, G. 2003. Effects of life history variation on size and growth in stream-dwelling Atlantic salmon. J. Fish Biol. 62(1): 97–114. doi:10.1046/j.0022-1112.2003.00009.x. Xu, C.L., Letcher, B.H., and Nislow, K.H. 2010. Size-dependent survival of brook trout Salvelinus fontinalis in summer: effects of water temperature and stream flow. J. Fish Biol. 76(10): 2342–2369. doi:10.1111/j.1095-8649.2010.02619.x. O’Donnell, M.J., and Letcher, B.H. 2017. Implanting 8-mm passive integrated transponder tags into small Brook Trout: Effects on growth and survival in the laboratory. North Am. J. Fish. Manag. 37(3): 605–611. Taylor &amp; Francis. doi:10.1080/02755947.2017.1307291. Zydlewski, G.B., Horton, G.E., Dubreuil, T.L., Letcher, B.H., Casey, S., and Zydlewski, J. 2006. Remote Monitoring of Fish in Small Streams: a unified approach using PIT tags. Fisheries 31(10): 492–502. doi:10.1577/1548-8446(2006)31[492:RMOFIS]2.0.CO;2. Sigourney, D.B., Letcher, B.H., Obedzinski, M., and Cunjak, R. a. 2013. Interactive effects of life history and season on size-dependent growth in juvenile Atlantic salmon. Ecol. Freshw. Fish 22(4): 495–507. doi:10.1111/eff.12042. Letcher, B.H., Hocking, D.J., O’Neil, K., Whiteley, A.R., Nislow, K.H., and O’Donnell, M.J. 2016. A hierarchical model of daily stream temperature using air-water temperature synchronization, autocorrelation, and time lags. PeerJ 4: e1727. doi:10.7717/peerj.1727. Horton, G.E., Dubreuil, T.L., and Letcher, B.H. 2007. A Model for Estimating Passive Integrated Transponder (PIT) Tag Antenna Efficiencies for Interval-Specific Emigration Rates. Trans. Am. Fish. Soc. 136(5): 1165–1176. doi:10.1577/T06-053.1. Bassar, R.D., Letcher, B.H., Nislow, K.H., and Whiteley, A.R. 2016. Changes in seasonal climate outpace compensatory density-dependence in eastern brook trout. Glob. Chang. Biol.: 577–593. doi:10.1111/gcb.13135. Letcher, B.H., Nislow, K.H., O’Donnell, M.J., Whiteley, A.R., Coombs, J.A., and Dubreuil, T.L. 2022. Cohort strength and body size in co-occurring salmonids in a small stream network: variation in space and time. Can. J. Fish. Aquat. Sci. 79(1): 133–147. doi:10.1139/cjfas-2020-0418. Letcher, B.H., Coombs, J. a., and Nislow, K.H. 2011. Maintenance of phenotypic variation: repeatability, heritability and size-dependent processes in a wild brook trout population. Evol. Appl. 4(4): 602–615. doi:10.1111/j.1752-4571.2011.00184.x. Letcher, B.H., Gries, G., and Juanes, F. 2002. Survival of Stream-Dwelling Atlantic Salmon: Effects of Life History Variation, Season, and Age. Trans. Am. Fish. Soc. 131(5): 838–854. doi:10.1577/1548-8659(2002)131&lt;0838:SOSDAS&gt;2.0.CO;2. Letcher, B.H. 2003. Life history dependent morphometric variation in stream-dwelling Atlantic salmon. Oecologia 137(4): 533–40. doi:10.1007/s00442-003-1387-0. Sigourney, D.B., Letcher, B.H., Obedzinski, M., and Cunjak, R.A. 2008. Size-independent growth in fishes: patterns, models and metrics. J. Fish Biol. 72(10): 2435–2455. doi:10.1111/j.1095-8649.2008.01830.x. Davidson, R.S., Letcher, B.H., and Nislow, K.H. 2010. Drivers of growth variation in juvenile Atlantic salmon ( Salmo salar ): an elasticity analysis approach. J. Anim. Ecol. 79(5): 1113–1121. doi:10.1111/j.1365-2656.2010.01708.x. Nislow, K.H., and Armstrong, J.D. 2012. Towards a life-history-based management framework for the effects of flow on juvenile salmonids in streams and rivers. Fish. Manag. Ecol. 19(6): 451–463. doi:10.1111/j.1365-2400.2011.00810.x. Whiteley, A.R., Coombs, J. a., Cembrola, M., O’Donnell, M.J., Hudy, M., Nislow, K.H., and Letcher, B.H. 2015. Effective number of breeders provides a link between interannual variation in stream flow and individual reproductive contribution in a stream salmonid. Mol. Ecol.: n/a-n/a. doi:10.1111/mec.13273. Letcher, B.H., Horton, G.E., Dubreuil, T.L., and Donnell, M.J.O. 2005. A field test of the extent of bias in selection estimates after accounting for emigration. Evol. Ecol.: 643–650. Pearlstein, J.H., Letcher, B.H., and Obedzinski, M. 2007. Early Discrimination of Atlantic Salmon Smolt Age: Time Course of the Relative Effectiveness of Body Size and Shape. Trans. Am. Fish. Soc. 136(6): 1622–1632. doi:10.1577/T07-010.1. Carlson, S.M., Hendry, A.P., and Letcher, B.H. 2004. Natural selection acting on body size , growth rate and compensatory growth : an empirical test in a wild trout population. Evol. Ecol.: 955–973. Letcher, B.H., Schueller, P., Bassar, R.D., Nislow, K.H., Coombs, J.A., Sakrejda, K., Morrissey, M., Sigourney, D.B., Whiteley, A.R., O’Donnell, M.J., and Dubreuil, T.L. 2015. Robust estimates of environmental effects on population vital rates: an integrated capture-recapture model of seasonal brook trout growth, survival and movement in a stream network. J. Anim. Ecol. 84(2): 337–352. doi:10.1111/1365-2656.12308. Carlson, S.M., Hendry, a. P., and Letcher, B.H. 2007. Growth rate differences between resident native brook trout and non-native brown trout. J. Fish Biol. 71(5): 1430–1447. doi:10.1111/j.1095-8649.2007.01615.x. O’Donnell, M.J., Horton, G.E., and Letcher, B.H. 2010. Use of Portable Antennas to Estimate Abundance of PIT-Tagged Fish in Small Streams: Factors Affecting Detection Probability. North Am. J. Fish. Manag. 30: 323–336. doi:10.1577/M09-008.1. Letcher, B.H., Nislow, K.H., Coombs, J., O’Donnell, M.J., and Dubreuil, T.L. 2007. Population response to habitat fragmentation in a stream-dwelling brook trout population. PLoS One 2(11): e1139. doi:10.1371/journal.pone.0001139. Carlson, S.M., and Letcher, B.H. 2003. Variation in brook and brown trout survival within and among seasons, species, and age classes. J. Fish Biol. 63(3): 780–794. doi:10.1046/j.1095-8649.2003.00191.x. Hendry, A.P., Letcher, B.H., and Gries, G. 2003. Estimating Natural Selection Acting on Stream-Dwelling Atlantic Salmon: Implications for the Restoration of Extirpated Populations. Conserv. Biol. 17(3): 795–805. doi:10.1046/j.1523-1739.2003.02075.x. Letcher, B.H., Schueller, P., Bassar, R.D., Nislow, K.H., Coombs, J. a, Sakrejda, K., Morrissey, M., Sigourney, D.B., Whiteley, A.R., O’Donnell, M.J., and Dubreuil, T.L. 2015. Robust estimates of environmental effects on population vital rates: an integrated capture-recapture model of seasonal brook trout growth, survival and movement in a stream network. J. Anim. Ecol. 84(2): 337–352. doi:10.1111/1365-2656.12308. Letcher, B.H., and Horton, G.E. 2008. Seasonal variation in size-dependent survival of juvenile Atlantic salmon (Salmo salar): performance of multistate capture-mark-recapture models. Can. J. Fish. Aquat. Sci. 65(8): 1649–1666. doi:10.1139/F08-083. Horton, G.E., Letcher, B.H., Bailey, M.M., and Kinnison, M.T. 2009. Atlantic salmon (Salmo salar) smolt production: the relative importance of survival and body growth. Can. J. Fish. Aquat. Sci. 66(3): 471–483. doi:10.1139/F09-005. Scace, J.G., Letcher, B.H., and Noreika, J. 2007. An Efficient Smolt Trap for Sandy and Debris-Laden Streams. North Am. J. Fish. Manag. 27(4): 1276–1286. doi:10.1577/M07-036.1. Gries, G., and Letcher, B.H. 2002. A Night Seining Technique for Sampling Juvenile Atlantic Salmon in Streams. North Am. J. Fish. Manag. 22(2): 595–601. doi:10.1577/1548-8675(2002)022&lt;0595:ANSTFS&gt;2.0.CO;2. Childress, E.S., and Letcher, B.H. 2017. Estimating thermal performance curves from repeated field observations. Ecology 98(5): 1377–1387. doi:10.1002/ecy.1801. Aubin-Horth, N., Letcher, B.H., and Hofmann, H. a. 2009. Gene-expression signatures of Atlantic salmon’s plastic life cycle. Gen. Comp. Endocrinol. 163(3): 278–84. Elsevier Inc. doi:10.1016/j.ygcen.2009.04.021. Childress, E.S., Nislow, K.H., Whiteley, A.R., O’Donnell, M.J., and Letcher, B.H. 2019. Daily estimates reveal fine-scale temporal and spatial variation in fish survival across a stream network. Can. J. Fish. Aquat. Sci. 76(8): 1446–1458. doi:10.1139/cjfas-2018-0191. Kanno, Y., Letcher, B.H., Coombs, J. a., Nislow, K.H., and Whiteley, A.R. 2014. Linking movement and reproductive history of brook trout to assess habitat connectivity in a heterogeneous stream network. Freshw. Biol. 59(1): 142–154. doi:10.1111/fwb.12254. Horton, G.E., Letcher, B.H., and Kendall, W.L. 2011. A Multistate Capture–Recapture Modeling Strategy to Separate True Survival from Permanent Emigration for a Passive Integrated Transponder Tagged Population of Stream Fish. Trans. Am. Fish. Soc. 140(2): 320–333. doi:10.1080/00028487.2011.567861. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
